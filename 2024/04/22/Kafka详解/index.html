<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-128x128.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-64x64.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Roboto:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-center-simple.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"irvlin.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"default"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Kafka详解">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka详解">
<meta property="og:url" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/index.html">
<meta property="og:site_name" content="IRvLin的博客">
<meta property="og:description" content="Kafka详解">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E7%BB%93%E6%9E%84.jpg">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E5%89%8A%E5%B3%B0.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E8%A7%A3%E8%80%A6.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E5%BC%82%E6%AD%A5%E9%80%9A%E4%BF%A1.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E7%82%B9%E5%AF%B9%E7%82%B9.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E5%8F%91%E5%B8%83-%E8%AE%A2%E9%98%85.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E5%8F%91%E9%80%81%E5%8E%9F%E7%90%86.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/main%E7%BA%BF%E7%A8%8B%E5%88%9D%E5%A7%8B%E5%8C%96.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/sender%E7%BA%BF%E7%A8%8B%E5%88%9D%E5%A7%8B%E5%8C%96.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/main%E7%BA%BF%E7%A8%8B%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE%E5%88%B0%E7%BC%93%E5%86%B2%E5%8C%BA.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/sender%E7%BA%BF%E7%A8%8B%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E5%88%86%E5%8C%BA.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E5%B9%82%E7%AD%89.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E7%94%9F%E4%BA%A7%E8%80%85%E4%BA%8B%E5%8A%A1.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E6%95%B0%E6%8D%AE%E6%9C%89%E5%BA%8F.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/broker%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/leader%E9%80%89%E4%B8%BE.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/LEOHW.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/LEOHW2.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/LEOHW3.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/LEOHW4.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/LEOHW5.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/LEOHW6.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/topic%E5%AD%98%E5%82%A8.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/logindex.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/log-index.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E5%8E%8B%E7%BC%A9.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E9%AB%98%E6%95%88%E8%AF%BB%E5%86%99.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E9%9B%B6%E6%8B%B7%E8%B4%9D.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E6%8E%A8.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E6%B6%88%E8%B4%B9%E8%80%85%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E6%B6%88%E8%B4%B9%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%9D%E5%A7%8B%E5%8C%96.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E6%B6%88%E8%B4%B9%E8%80%85%E8%AE%A2%E9%98%85%E4%B8%BB%E9%A2%98.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E6%B6%88%E8%B4%B9%E8%80%85%E6%8B%89%E5%8F%96%E5%B9%B6%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E5%88%86%E5%8C%BA%E5%B9%B3%E8%A1%A1.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/range.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E8%BD%AE%E8%AF%A2.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/offset.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%E5%92%8C%E6%BC%8F%E6%B6%88%E8%B4%B9.png">
<meta property="article:published_time" content="2024-04-21T16:20:30.000Z">
<meta property="article:modified_time" content="2024-04-22T04:51:39.581Z">
<meta property="article:author" content="Charispsychoma">
<meta property="article:tag" content="Kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/%E7%BB%93%E6%9E%84.jpg">

<link rel="canonical" href="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Kafka详解 | IRvLin的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">IRvLin的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger">
            <i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    

  <a href="https://github.com/irvlin" class="github-corner" title="Fork me on GitHub" aria-label="Fork me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://irvlin.github.io/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Charispsychoma">
      <meta itemprop="description" content="Stay hungry. Stay foolish.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="IRvLin的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kafka详解
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2024-04-22 00:20:30 / 修改时间：12:51:39" itemprop="dateCreated datePublished" datetime="2024-04-22T00:20:30+08:00">2024-04-22</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Kafka/" itemprop="url" rel="index"><span itemprop="name">Kafka</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/04/22/Kafka%E8%AF%A6%E8%A7%A3/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Kafka详解</p>
<a id="more"></a>

<h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Kafka最初是由Linkedin公司开发的，是一个分布式的、可扩展的、容错的、支持分区的（Partition）、多副本的（replica）、基于Zookeeper框架的发布-订阅消息系统，Kafka适合离线和在线消息消费。它是分布式应用系统中的重要组件之一，也被广泛应用于大数据处理。Kafka是用Scala语言开发，它的Java版本称为Jafka。Linkedin于2010年将该系统贡献给了Apache基金会并成为顶级开源项目之一。</p>
<p><img src="%E7%BB%93%E6%9E%84.jpg" alt="结构"></p>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><ul>
<li><strong>Kafka传统定义</strong>：Kafka是一个<strong>分布式</strong>的<strong>基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域</strong>。使用Scala语言编写，是Apache的顶级项目。</li>
</ul>
<p>  <strong>发布/订阅</strong>：消息的发布者不会将消息直接发送给特定的订阅者，而是将发布的消息分为不同的类别，订阅者只接收感兴趣的信息。</p>
<ul>
<li><strong>Kafka最新定义</strong>：Kafka是一个开源的<strong>分布式事件流平台（Event Streaming Platform），主要应用于高性能数据管道、流分析、数据集成和关键任务应用。</strong></li>
</ul>
<h3 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h3><h4 id="传统消息队列的应用场景"><a href="#传统消息队列的应用场景" class="headerlink" title="传统消息队列的应用场景"></a>传统消息队列的应用场景</h4><p>传统的消息队列的主要应用场景包括:缓冲/消峰、解耦和异步通信。</p>
<ul>
<li><p>缓冲/消峰：有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。</p>
<p><img src="%E5%89%8A%E5%B3%B0.png" alt="削峰"></p>
</li>
<li><p>解耦：允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p>
<p><img src="%E8%A7%A3%E8%80%A6.png" alt="解耦"></p>
</li>
<li><p>异步通信：允许用户把一个消息放入队列，但并不立即处理它，然后在需要的时候再去处理它们。</p>
<p><img src="%E5%BC%82%E6%AD%A5%E9%80%9A%E4%BF%A1.png" alt="异步通信"></p>
</li>
</ul>
<h4 id="两种模式"><a href="#两种模式" class="headerlink" title="两种模式"></a>两种模式</h4><h5 id="点对点模式"><a href="#点对点模式" class="headerlink" title="点对点模式"></a>点对点模式</h5><p>消费者主动拉取数据，消息收到之后清除消息。</p>
<p><img src="%E7%82%B9%E5%AF%B9%E7%82%B9.png" alt="点对点"></p>
<h5 id="发布-订阅模式"><a href="#发布-订阅模式" class="headerlink" title="发布-订阅模式"></a>发布-订阅模式</h5><ol>
<li>可以有多个topic主题</li>
<li>消费者消费数据之后，不删除数据</li>
<li>每个消费者相互独立，都可以消费到数据</li>
</ol>
<p><img src="%E5%8F%91%E5%B8%83-%E8%AE%A2%E9%98%85.png" alt="发布-订阅"></p>
<h3 id="基础架构"><a href="#基础架构" class="headerlink" title="基础架构"></a>基础架构</h3><p><img src="%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84.png" alt="基础架构"></p>
<ol>
<li><strong>Producer</strong>：消息生产者，就是向Kafka broker发消息的客户端。</li>
<li><strong>Consumer</strong>：消息消费者，向Kafka broker 获取消息的客户端。</li>
<li><strong>Consumer Group（CG）</strong>：消费者组，由多个consumer组成。<strong>消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费</strong>；消费者组之间互不影响，所有的消费者都属于某个消费者组，<strong>即消费者组是逻辑上的一个订阅者。</strong></li>
<li><strong>Broker</strong>：一台Kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。</li>
<li><strong>Topic</strong>：可以理解为一个队列，生产者和消费者面向的都是一个topic。</li>
<li><strong>Partition</strong>：<strong>为了实现扩展性</strong>，<strong>一个非常大的topic可以分布到多个broker（即服务器）上</strong>，<strong>一个topic可以分为多个partition，每个partition是一个有序的队列。</strong></li>
<li><strong>Replica</strong>：副本。<strong>一个 topic 的每个分区都有若干个副本，一个 Leader 和若干个 Follower</strong>。</li>
<li>Leader：<strong>每个分区多个副本的“主”</strong>，<strong>生产者发送数据的对象，以及消费者消费数据的对象都是Leader</strong>。</li>
<li>Follower：每个分区多个副本中的“从”，实时从Leader中同步数据，保持和Leader数据的同步。Leader发生故障时，某个Follower会成为新的Leader。</li>
</ol>
<h2 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h2><h3 id="消息发送流程"><a href="#消息发送流程" class="headerlink" title="消息发送流程"></a>消息发送流程</h3><p>在消息发送的过程中，涉及到了两个线程——main线程和Sender线程。在main线程中创建了一个双端队列RecordAccumulator（默认32m）。main线程将消息发送给RecordAccumulator，Sender线程不断从RecordAccumulator中拉取消息发送到Kafka Broker。</p>
<p><img src="%E5%8F%91%E9%80%81%E5%8E%9F%E7%90%86.png" alt="发送原理"></p>
<p>main线程初始化：</p>
<p><img src="main%E7%BA%BF%E7%A8%8B%E5%88%9D%E5%A7%8B%E5%8C%96.png" alt="main线程初始化"></p>
<p>sender线程初始化：</p>
<p><img src="sender%E7%BA%BF%E7%A8%8B%E5%88%9D%E5%A7%8B%E5%8C%96.png" alt="sender线程初始化"></p>
<p>main线程发送数据到缓冲区：</p>
<p><img src="main%E7%BA%BF%E7%A8%8B%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE%E5%88%B0%E7%BC%93%E5%86%B2%E5%8C%BA.png" alt="main线程发送数据到缓冲区"></p>
<p>sender线程发送数据：</p>
<p><img src="sender%E7%BA%BF%E7%A8%8B%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE.png" alt="sender线程发送数据"></p>
<h3 id="参数列表"><a href="#参数列表" class="headerlink" title="参数列表"></a>参数列表</h3><table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong>bootstrap.servers</strong></td>
<td><strong>生产者连接集群所需的broker地址清单</strong>。例如kafka1:9092,kafka2:9092,kafka3:9092，可以设置1个或者多个，中间用逗号隔开。注意这里并非需要所有的broker地址，因为生产者从给定的broker里查找到其他broker信息。</td>
</tr>
<tr>
<td>key.serializer和value.serializer</td>
<td>指定发送消息的key和value的序列化类型。<strong>一定要写全类名</strong>。</td>
</tr>
<tr>
<td><strong>buffer.memory</strong></td>
<td>RecordAccumulator<strong>缓冲区总大小，默认32m。</strong></td>
</tr>
<tr>
<td><strong>batch.size</strong></td>
<td>缓冲区一批数据最大值，<strong>默认16k</strong>。<strong>适当增加该值，可以提高吞吐量，但是如果该值设置太大，会导致数据传输延迟增加。</strong></td>
</tr>
<tr>
<td><strong>linger.ms</strong></td>
<td><strong>如果数据迟迟未达到batch.size，sender等待linger.time之后就会发送数据</strong>。<strong>单位ms，默认值是0ms</strong>，表示没有延迟。生产环境建议该值大小为5-100ms之间。</td>
</tr>
<tr>
<td><strong>acks</strong></td>
<td>0：生产者发送过来的数据，<strong>不需要等数据落盘应答。</strong>  1：生产者发送过来的数据，<strong>Leader收到数据后应答。</strong>  -1（all）：生产者发送过来的数据，<strong>Leader+和isr队列里面的所有节点收齐数据后应答</strong>。<strong>默认值是-1，-1和all是等价的</strong>。</td>
</tr>
<tr>
<td><strong>max.in.flight.requests.per.connection</strong></td>
<td><strong>允许最多没有返回ack的次数</strong>，<strong>默认为5</strong>，<strong>开启幂等性要保证该值是 1-5的数字。</strong></td>
</tr>
<tr>
<td>retries</td>
<td>当消息发送出现错误的时候，系统会重发消息。<strong>retries表示重试次数</strong>。默认是int最大值，2147483647。 <strong>如果设置了重试，还想保证消息的有序性，需要设置MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION=1，否则在重试此失败消息的时候，其他的消息可能发送成功了</strong>。</td>
</tr>
<tr>
<td>retry.backoff.ms</td>
<td>两次重试之间的时间间隔，默认是100ms。</td>
</tr>
<tr>
<td><strong>enable.idempotence</strong></td>
<td><strong>是否开启幂等性，默认true，开启幂等性</strong>。</td>
</tr>
<tr>
<td>compression.type</td>
<td>生产者发送的所有数据的压缩方式。<strong>默认是none，也就是不压缩。</strong> 支持压缩类型：<strong>none、gzip、snappy、lz4和zstd。</strong></td>
</tr>
</tbody></table>
<h3 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h3><h4 id="分区好处"><a href="#分区好处" class="headerlink" title="分区好处"></a>分区好处</h4><ol>
<li>便于合理使用存储资源，每个Partition在一个Broker上存储，可以把海量的数据按照分区切割成一块一块数据存储在多台Broker上。合理控制分区的任务，可以实现负载均衡的效果。</li>
<li>提高并行度，生产者可以以分区为单位发送数据；消费者可以以分区为单位进行消费数据。</li>
</ol>
<p><img src="%E5%88%86%E5%8C%BA.png" alt="分区"></p>
<h4 id="分区策略"><a href="#分区策略" class="headerlink" title="分区策略"></a>分区策略</h4><ol>
<li>指明partition的情况下，直接将指明的值作为partition值；例如partition=0，所有数据写入分区0。</li>
<li>没有指明partition值但有key的情况下，将key的hash值与topic的partition数进行取余得到partition值；例如：key1的hash值=5，key2的hash值=6，topic的partition数=2，那么key1对应的value1写入1号分区，key2对应的value2写入0号分区。</li>
<li>既没有partition值又没有key值的情况下，Kafka采用StickyPartition（黏性分区器），会随机选择一个分区，并尽可能一直使用该分区，待该分区的batch已满或者已完成，Kafka再随机选择一个分区进行使用（和上一次的分区不同）。例如：第一次随机选择0号分区，等0号分区当前批次满了（默认16k）或者linger.ms设置的时间到，Kafka再随机选择一个分区进行使用（如果还是0会继续随机）。</li>
</ol>
<h4 id="提高生产者吞吐量"><a href="#提高生产者吞吐量" class="headerlink" title="提高生产者吞吐量"></a>提高生产者吞吐量</h4><ol>
<li>batch.size：修改批次大小，默认16K</li>
<li>linger.ms：修改等待时间，默认0</li>
<li>RecordAccumulator：修改缓冲区大小，默认32M：buffer.memory</li>
<li>compression.type：修改压缩，默认none，可配置值：gzip、snappy、lz4和zstd</li>
</ol>
<h4 id="提高数据可靠性"><a href="#提高数据可靠性" class="headerlink" title="提高数据可靠性"></a>提高数据可靠性</h4><h5 id="ACK"><a href="#ACK" class="headerlink" title="ACK"></a>ACK</h5><ol>
<li>acks：0，生产者发送过来的数据，不需要等数据落盘应答。Leader节点收到消息之后，在数据落盘之前就挂掉了，则会导致数据丢失。数据可靠性分析：数据丢失。</li>
<li>acks：1，生产者发送过来的数据，Leader收到数据后应答。应答完成之后，还没开始同步副本，Leader节点就挂掉了，新的Leader不会再收到之前发送的消息，因为生产者已经认为消息发送成功了。 数据可靠性分析：数据丢失。</li>
<li>acks：-1（all）：生产者发送过来的数据，Leader和ISR队列里面的所有节点收齐数据后应答。</li>
</ol>
<p>思考：acks：-1（all），Leader收到数据，所有Follower都开始同步数据，但有一个Follower，因为某种故障，迟迟不能与Leader进行同步，那这个问题怎么解决呢？</p>
<p>Leader维护了一个动态的in-syncreplicaset（ISR），意为和Leader保持同步的Follower+Leader集合(leader：0，isr:0,1,2)。如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值由replica.lag.time.max.ms参数设定，默认30s。例如2超时，(leader:0, isr:0,1)。这样就不用等长期联系不上或者已经故障的节点。</p>
<p>acks：-1（all）数据可靠性分析：</p>
<ul>
<li>如果分区副本设置为1个，或者ISR里应答的最小副本数量（min.insync.replicas默认为1）设置为1，和ack=1的效果是一样的，仍然有丢数的风险（leader: 0，isr: 0）。</li>
<li>数据完全可靠条件=ACK级别设置为-1+分区副本大于等于2+ISR里应答的最小副本数量大于等于2。</li>
</ul>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul>
<li>acks=0，生产者发送过来数据就不管了，可靠性差，效率高。</li>
<li>acks=1，生产者发送过来数据Leader应答，可靠性中等，效率中等。</li>
<li>acks=-1，生产者发送过来数据Leader和ISR队列里面所有Follwer应答，可靠性高，效率低。</li>
</ul>
<p>在生产环境中，acks=0很少使用；acks=1，一般用于传输普通日志，允许丢个别数据；acks=-1，一般用于传输和钱相关的数据，对可靠性要求比较高的场景。</p>
<h3 id="数据去重"><a href="#数据去重" class="headerlink" title="数据去重"></a>数据去重</h3><h4 id="传递语义"><a href="#传递语义" class="headerlink" title="传递语义"></a>传递语义</h4><ul>
<li>至少一次（AtLeastOnce）=ACK级别设置为-1+分区副本大于等于2+ISR里应答的最小副本数量大于等于2。可以保证数据不丢失，但是不能保证数据不重复；</li>
<li>最多一次（AtMostOnce）=ACK级别设置为0。可以保证数据不重复，但是不能保证数据不丢失。</li>
<li>精确一次（ExactlyOnce）：精确一次（ExactlyOnce）=幂等性+至少一次（ack=-1+分区副本数&gt;=2+ISR最小副本数量&gt;=2）。对于一些非常重要的信息，比如和钱相关的数据，要求数据既不能重复也不丢失。</li>
</ul>
<p>Kafka0.11版本以后，引入了一项重大特性：幂等性和事务。</p>
<h4 id="幂等"><a href="#幂等" class="headerlink" title="幂等"></a>幂等</h4><p>幂等性：就是指Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一条，保证了不重复。</p>
<p>重复数据的判断标准：具有&lt;PID,Partition,SeqNumber&gt;相同主键的消息提交时，Broker只会持久化一条。其中PID是Kafka每次重启都会分配一个新的；Partition表示分区号；SequenceNumber是单调自增的。</p>
<p>所以幂等性只能保证的是在单分区单会话内不重复。</p>
<p><img src="%E5%B9%82%E7%AD%89.png" alt="幂等"></p>
<p><strong>如何使用幂等性？</strong></p>
<p>开启参数enable.idempotence 默认为true，false关闭。</p>
<h4 id="生产者事务"><a href="#生产者事务" class="headerlink" title="生产者事务"></a>生产者事务</h4><p>Kafka事务原理，开启事务，必须开启幂等性。</p>
<p><img src="%E7%94%9F%E4%BA%A7%E8%80%85%E4%BA%8B%E5%8A%A1.png" alt="生产者事务"></p>
<h3 id="数据有序"><a href="#数据有序" class="headerlink" title="数据有序"></a>数据有序</h3><ol>
<li>单分区内，有序。多分区内，分区与分区间无序。</li>
<li>kafka在1.x版本之前，保证数据单分区内有序，条件如下：<ol>
<li>max.in.flight.requests.per.connection=1（不需要考虑是否开启幂等性）。</li>
</ol>
</li>
<li>kafka在1.x及以后版本保证数据单分区有序，条件如下：<ol>
<li>未开启幂等性：max.in.flight.requests.per.connection需要设置为1。</li>
<li>开启幂等性：max.in.flight.requests.per.connection需要设置小于等于5。因为在kafka1.x以后，启用幂等后，kafka服务端会缓存producer发来的最近5个request的元数据，故无论如何，都可以保证最近5个request的数据都是有序的。</li>
</ol>
</li>
</ol>
<p><img src="%E6%95%B0%E6%8D%AE%E6%9C%89%E5%BA%8F.png" alt="数据有序"></p>
<h2 id="broker"><a href="#broker" class="headerlink" title="broker"></a>broker</h2><h3 id="broker工作流程"><a href="#broker工作流程" class="headerlink" title="broker工作流程"></a>broker工作流程</h3><p><img src="broker%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="broker工作流程"></p>
<ol>
<li>broker启动后在zk中注册</li>
<li>controller谁先注册，谁说了算</li>
<li>由选举出来的controller监听brokers节点变化</li>
<li>controller决定Leader选举</li>
<li>controller将节点信息上传到zk中</li>
<li>其他controller从zk同步相关信息</li>
<li>假设broker1中Leader挂了</li>
<li>controller监听到节点发生变化</li>
<li>获取ISR</li>
<li>选举新的Leader（在isr中存活为前提，按照AR中排在前面的优先，例如：ar[1,0,2]，那么leader就会按照1,0,2的顺序轮询）</li>
<li>更新Leader及ISR</li>
</ol>
<h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong>replica.lag.time.max.ms</strong></td>
<td><strong>ISR中，如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值</strong>，<strong>默认30s</strong>。</td>
</tr>
<tr>
<td>auto.leader.rebalance.enable</td>
<td>默认是true。 自动Leader Partition 平衡。</td>
</tr>
<tr>
<td>leader.imbalance.per.broker.percentage</td>
<td>默认是10%。每个broker允许的不平衡的leader的比率。如果每个broker超过了这个值，控制器会触发leader的平衡。</td>
</tr>
<tr>
<td>leader.imbalance.check.interval.seconds</td>
<td>默认值300秒。检查leader负载是否平衡的间隔时间。</td>
</tr>
<tr>
<td>log.segment.bytes</td>
<td>Kafka中log日志是分成一块块存储的，此配置是指log日志划分 成块的大小，默认值1G。</td>
</tr>
<tr>
<td><strong>log.index.interval.bytes</strong></td>
<td><strong>默认4kb，kafka里面每当写入了4kb大小的日志（.log），然后就往index文件里面记录一个索引。</strong></td>
</tr>
<tr>
<td>log.retention.hours</td>
<td>Kafka中数据保存的时间，默认7天。</td>
</tr>
<tr>
<td>log.retention.minute</td>
<td>Kafka中数据保存的时间，分钟级别，默认关闭。</td>
</tr>
<tr>
<td>log.retention.ms</td>
<td>Kafka中数据保存的时间，毫秒级别，默认关闭。</td>
</tr>
<tr>
<td>log.retention.check.interval.ms</td>
<td>检查数据是否保存超时的间隔，默认是5分钟。</td>
</tr>
<tr>
<td>log.retention.bytes</td>
<td>默认等于-1，表示无穷大。超过设置的所有日志总大小，删除最早的segment。</td>
</tr>
<tr>
<td>log.cleanup.policy</td>
<td>默认是delete，表示所有数据启用删除策略； 如果设置值为compact，表示所有数据启用压缩策略。</td>
</tr>
<tr>
<td><strong>num.io.threads</strong></td>
<td><strong>默认是8。负责写磁盘的线程数。整个参数值要占总核数的50%。</strong></td>
</tr>
<tr>
<td><strong>num.replica.fetchers</strong></td>
<td><strong>副本拉取线程数，这个参数占总核数的50%的1/3 。</strong></td>
</tr>
<tr>
<td>num.network.threads</td>
<td>强制页缓存刷写到磁盘的条数，默认是long的最大值，9223372036854775807。一般不建议修改， 交给系统自己管理。</td>
</tr>
<tr>
<td>log.flush.interval.ms</td>
<td>每隔多久，刷数据到磁盘，默认是null。一般不建议修改，交给系统自己管理。</td>
</tr>
</tbody></table>
<h3 id="副本"><a href="#副本" class="headerlink" title="副本"></a>副本</h3><h4 id="Kafka副本"><a href="#Kafka副本" class="headerlink" title="Kafka副本"></a>Kafka副本</h4><ol>
<li><strong>Kafka副本作用：提高数据可靠性。</strong></li>
<li>Kafka默认副本1个，生产环境一般配置为2个，保证数据可靠性；太多副本会增加磁盘存储空间，增加网络上数据传输，降低效率。</li>
<li>Kafka中副本分为：Leader和Follower。Kafka生产者只会把数据发往Leader，然后Follower找Leader进行同步数据。 </li>
<li><strong>Kafka分区中的所有副本统称为AR（Assigned Repllicas），AR = ISR + OSR。</strong><ol>
<li><strong>ISR，表示和Leader保持同步的Follower集合</strong>。<strong>如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值由replica.lag.time.max.ms参数设定，默认30s</strong>。Leader发生故障之后，就会从ISR中选举新的Leader。</li>
<li><strong>OSR，表示Follower与Leader副本同步时，延迟过多的副本。</strong></li>
</ol>
</li>
</ol>
<h4 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h4><p>Kafka集群中有一个broker的Controller会被选举为Controller Leader，负责管理集群broker的上下线，所有topic的分区副本分配和Leader选举等工作。Controller的信息同步工作是依赖于Zookeeper的。 </p>
<p><img src="leader%E9%80%89%E4%B8%BE.png" alt="leader选举"></p>
<h4 id="Leader和Follower故障处理细节"><a href="#Leader和Follower故障处理细节" class="headerlink" title="Leader和Follower故障处理细节"></a>Leader和Follower故障处理细节</h4><p>LEO（Log End Offset）：每个副本的最后一个offset，LEO其实就是最新的offset+1。</p>
<p>HW（High Watermark）：所有副本中最小的LEO。</p>
<p><img src="LEOHW.png" alt="LEOHW"></p>
<ol>
<li><p>Follower故障</p>
<p>1) Follower发生故障后会被临时踢出ISR。<br>2) 这个期间Leader和Follower继续接收数据。</p>
<p><img src="LEOHW2.png" alt="LEOHW"></p>
<ol start="3">
<li><p>待该Follower恢复后，Follower会读取本地磁盘记录上次的HW，并将log文件高于HW的部分截取掉，从HW开始向Leader进行同步。</p>
<p><img src="LEOHW3.png" alt="LEOHW"></p>
</li>
<li><p>等该Follower的LEO大于等于该Partition的HW，即Follower追上Leader之后，就可以重新加入ISR了。</p>
<p><img src="LEOHW4.png" alt="LEOHW4"></p>
</li>
</ol>
</li>
<li><p>Leader故障</p>
<ol>
<li><p>Leader发生故障之后，会从ISR中选出一个新的Leader。</p>
<p><img src="LEOHW5.png" alt="LEOHW"></p>
</li>
<li><p>为保证多个副本之间的数据一致性，其余的Follower会先将各自的log文件高于HW的部分截掉，然后从新的Leader同步数据。</p>
<p><img src="LEOHW6.png" alt=""></p>
</li>
</ol>
</li>
</ol>
<p>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</p>
<h3 id="文件存储"><a href="#文件存储" class="headerlink" title="文件存储"></a>文件存储</h3><h4 id="文件存储机制"><a href="#文件存储机制" class="headerlink" title="文件存储机制"></a>文件存储机制</h4><p>Topic数据存储机制</p>
<p>Topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是Producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引机制，将每个partition分为多个segment。每个segment包括：“.index”文件、“.log”文件和.timeindex等文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称+分区序号，例如：first-0。</p>
<p><img src="topic%E5%AD%98%E5%82%A8.png" alt="topic存储"></p>
<ul>
<li>.log：日志文件</li>
<li>.index：偏移量索引文件</li>
<li>.timeindex：时间戳索引文件</li>
</ul>
<p><img src="logindex.png" alt="logindex"></p>
<p>log文件和index文件</p>
<p><img src="log-index.png" alt="log-index"></p>
<table>
<thead>
<tr>
<th>日志存储参数配置</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>参数名称</td>
<td>描述</td>
</tr>
<tr>
<td>log.segment.bytes</td>
<td>Kafka中log日志是分成一块块存储的，此配置是指log日志划分成块的大小，默认值1G。</td>
</tr>
<tr>
<td>log.index.interval.bytes</td>
<td><strong>默认4kb</strong>，kafka里面每当写入了4kb大小的日志（.log），然后就往index文件里面记录一个索引。 <strong>稀疏索引。</strong></td>
</tr>
</tbody></table>
<h4 id="文件清理策略"><a href="#文件清理策略" class="headerlink" title="文件清理策略"></a>文件清理策略</h4><p>Kafka中默认的日志保存时间为7天，可以通过调整如下参数修改保存时间。</p>
<ul>
<li>log.retention.hours，最低优先级小时，默认7天。</li>
<li>log.retention.minutes，分钟。 </li>
<li>log.retention.ms，最高优先级毫秒。 </li>
<li>log.retention.check.interval.ms，负责设置检查周期，默认5分钟。</li>
</ul>
<p>Kafka中提供的日志清理策略有<strong>delete和compact</strong>两种。 </p>
<p>（1）<strong>delete日志删除</strong>：将过期数据删除。log.cleanup.policy = delete   所有数据启用删除策略。</p>
<p>​    a. 基于时间：默认打开。以segment中所有记录中的最大时间戳作为该文件时间戳。 </p>
<p>​    b. 基于大小：默认关闭。超过设置的所有日志总大小，删除最早的segment。log.retention.bytes，默认等于-1，表示无穷大。 </p>
<p>（2）<strong>compact日志压缩</strong>：<strong>compact日志压缩：对于相同key的不同value值，只保留最后一个版本</strong>。log.cleanup.policy=compact所有数据启用压缩策略。</p>
<p><img src="%E5%8E%8B%E7%BC%A9.png" alt="压缩"></p>
<p>压缩后的offset可能是不连续的，比如上图中没有6，当从这些offset消费消息时，将会拿到比这个offset大的offset对应的消息，实际上会拿到offset为7的消息，并从这个位置开始消费。<br>这种策略只适合特殊场景，比如消息的key是用户ID，value是用户的资料，通过这种压缩策略，整个消息集里就保存了所有用户最新的资料。</p>
<h4 id="高效读写数据"><a href="#高效读写数据" class="headerlink" title="高效读写数据"></a>高效读写数据</h4><ol>
<li>Kafka是分布式集群，可以采用分区技术，并行度高。</li>
<li>读数据采用稀疏索引，可以快速定位到要消费的数据。</li>
<li>顺序写磁盘。</li>
</ol>
<p>Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到600M/s，而随机写只有100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。</p>
<p><img src="%E9%AB%98%E6%95%88%E8%AF%BB%E5%86%99.png" alt="高效读写"></p>
<h4 id="PageCache-零拷贝"><a href="#PageCache-零拷贝" class="headerlink" title="PageCache+零拷贝"></a>PageCache+零拷贝</h4><p><strong>零拷贝：</strong>Kafka的数据加工处理操作交由Kafka生产者和Kafka消费者处理。Kafka Broker应用层不关心存储的数据，所以就不用走应用层，传输效率高。</p>
<p><strong>PageCache页缓存</strong>：Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入PageCache。当读操作发生时，先从PageCache中查找，如果找不到，再去磁盘中读取。<strong>实际上PageCache是把尽可能多的空闲内存都当做了磁盘缓存来使用。</strong></p>
<p><img src="%E9%9B%B6%E6%8B%B7%E8%B4%9D.png" alt="零拷贝"></p>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>log.flush.interval.messages</td>
<td>强制页缓存刷写到磁盘的条数，默认是long的最大值，9223372036854775807。一般不建议修改，交给系统自己管理。</td>
</tr>
<tr>
<td>log.flush.interval.ms</td>
<td>每隔多久，刷数据到磁盘，默认是null。一般不建议修改，交给系统自己管理。</td>
</tr>
</tbody></table>
<h2 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h2><h3 id="Kafka消费方式"><a href="#Kafka消费方式" class="headerlink" title="Kafka消费方式"></a>Kafka消费方式</h3><h4 id="拉"><a href="#拉" class="headerlink" title="拉"></a>拉</h4><p>consumer采用从broker中主动拉取数据。Kafka采用这种方式。pull模式不足之处是，如果Kafka没有数据，消费者可能会陷入循环中，一直返回空数据。</p>
<h4 id="推"><a href="#推" class="headerlink" title="推"></a>推</h4><p>Kafka没有采用这种方式，因为由broker决定消息发送速率，很难适应所有消费者的消费速率。例如推送的速度是50m/s，Consumer1、Consumer2就来不及处理消息。</p>
<p><img src="%E6%8E%A8.png" alt="推"></p>
<h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><p><img src="%E6%B6%88%E8%B4%B9%E8%80%85%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="消费者工作流程"></p>
<h4 id="消费者组"><a href="#消费者组" class="headerlink" title="消费者组"></a>消费者组</h4><p>ConsumerGroup（CG）：消费者组，由多个consumer组成。形成一个消费者组的条件，是所有消费者的groupid相同。</p>
<ul>
<li>消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费。</li>
<li>消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</li>
</ul>
<p><img src="%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84.png" alt="消费者组"></p>
<h4 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h4><p>coordinator：辅助实现消费者组的初始化和分区的分配。coordinator节点选择= groupid的hashcode值% 50（__consumer_offsets的分区数量）。</p>
<p>例如：groupid的hashcode值= 1，1% 50 = 1，那么__consumer_offsets主题的1号分区，在哪个broker上，就选择这个节点的coordinator作为这个消费者组的老大。消费者组下的所有的消费者提交offset的时候就往这个分区去提交offset。</p>
<p><img src="%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B.png" alt="初始化流程"></p>
<ol>
<li>每个consumer都发送JoinGroup请求。</li>
<li>选出一个consumer作为leader。</li>
<li>把要消费的topic情况发送给leader 消费者。</li>
<li>leader会负责制定消费方案。</li>
<li>把消费方案发给coordinator。</li>
<li>Coordinator就把消费方案下发给各个consumer。</li>
<li><strong>每个消费者都会和coordinator保持心跳（默认3s）**</strong>，一旦超时（session.timeout.ms=45s），该消费者会被移除，并触发再平衡；<strong>**或者消费者处理消息的时间过长（max.poll.interval.ms5分钟），也会触发再平衡</strong>。</li>
</ol>
<h4 id="消费流程"><a href="#消费流程" class="headerlink" title="消费流程"></a>消费流程</h4><p><img src="%E6%B6%88%E8%B4%B9%E6%B5%81%E7%A8%8B.png" alt="消费流程"></p>
<p>消费者初始化：</p>
<p><img src="%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%9D%E5%A7%8B%E5%8C%96.png" alt="消费者初始化"></p>
<p>消费者订阅主题：</p>
<p><img src="%E6%B6%88%E8%B4%B9%E8%80%85%E8%AE%A2%E9%98%85%E4%B8%BB%E9%A2%98.png" alt="消费者订阅主题"></p>
<p>消费者拉取、处理数据</p>
<p><img src="%E6%B6%88%E8%B4%B9%E8%80%85%E6%8B%89%E5%8F%96%E5%B9%B6%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE.png" alt="消费者拉取并处理数据"></p>
<h3 id="消费者参数"><a href="#消费者参数" class="headerlink" title="消费者参数"></a>消费者参数</h3><table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>bootstrap.servers</td>
<td>向Kafka集群建立初始连接用到的host/port列表。</td>
</tr>
<tr>
<td>key.deserializer/value.deserializer</td>
<td>指定接收消息的key和value的反序列化类型。一定要写全类名。</td>
</tr>
<tr>
<td>group.id</td>
<td>标记消费者所属的消费者组。</td>
</tr>
<tr>
<td>enable.auto.commit</td>
<td><strong>默认值为true</strong>，消费者会自动周期性地向服务器提交偏移量。</td>
</tr>
<tr>
<td>auto.commit.interval.ms</td>
<td>如果设置了 enable.auto.commit 的值为true， 则该值定义了消费者偏移量向Kafka提交的频率，<strong>默认5s</strong>。</td>
</tr>
<tr>
<td>auto.offset.reset</td>
<td>当Kafka中没有初始偏移量或当前偏移量在服务器中不存在（如，数据被删除了），该如何处理？ <strong>earliest</strong>：自动重置偏移量到最早的偏移量。 <strong>latest：默认</strong>，自动重置偏移量为最新的偏移量。 <strong>none</strong>：如果消费组原来的（previous）偏移量不存在，则向消费者抛异常。 anything：向消费者抛异常。</td>
</tr>
<tr>
<td>offsets.topic.num.partitions</td>
<td><strong>__consumer_offsets的分区数，默认是50个分区</strong>。</td>
</tr>
<tr>
<td>heartbeat.interval.ms</td>
<td><strong>Kafka消费者和coordinator之间的心跳时间，默认3s</strong>。 该条目的值必须小于 session.timeout.ms ，也不应该高于 session.timeout.ms 的1/3。</td>
</tr>
<tr>
<td>session.timeout.ms</td>
<td><strong>Kafka消费者和coordinator之间连接超时时间，默认45s。超过该值，该消费者被移除，消费者组执行再平衡。</strong></td>
</tr>
<tr>
<td>max.poll.interval.ms</td>
<td>消费者处理消息的最大时长，<strong>默认是5分钟</strong>。<strong>超过该值，该消费者被移除，消费者组执行再平衡。</strong></td>
</tr>
<tr>
<td><strong>fetch.min.bytes</strong></td>
<td><strong>默认1个字节</strong>。消费者获取服务器端一批消息最小的字节数。</td>
</tr>
<tr>
<td><strong>fetch.max.wait.ms</strong></td>
<td><strong>默认500ms</strong>。<strong>如果没有从服务器端获取到一批数据的最小字节数。该时间到，仍然会返回数据。</strong></td>
</tr>
<tr>
<td><strong>fetch.max.bytes</strong></td>
<td><strong>默认Defau**</strong>lt: 52428800（50 m）<strong>。消费者获取服务器端一批消息最大的字节数。</strong>如果服务器端一批次的数据大于该值（50m）仍然可以拉取回来这批数据，因此，这不是一个绝对最大值。一批次的大小受message.max.bytes （broker config）or max.message.bytes （topic config）影响。**</td>
</tr>
<tr>
<td><strong>max.poll.records</strong></td>
<td>一次poll拉取数据返回消息的最大条数，<strong>默认是500条。</strong></td>
</tr>
</tbody></table>
<h3 id="分区平衡以及再平衡"><a href="#分区平衡以及再平衡" class="headerlink" title="分区平衡以及再平衡"></a>分区平衡以及再平衡</h3><p>一个consumer group中有多个consumer组成，一个topic有多个partition组成。那么问题来了，到底由哪个consumer来消费哪个partition的数据？</p>
<p>Kafka有四种主流的分区分配策略：Range、RoundRobin、Sticky、CooperativeSticky。</p>
<p>可以通过配置参数partition.assignment.strategy，修改分区的分配策略。默认策略是Range +  CooperativeSticky。Kafka可以同时使用多个分区分配策略。</p>
<p><img src="%E5%88%86%E5%8C%BA%E5%B9%B3%E8%A1%A1.png" alt="分区平衡"></p>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>heartbeat.interval.ms</td>
<td><strong>Kafka消费者和coordinator之间的心跳时间，默认3s</strong>。 该条目的值必须小于 session.timeout.ms ，也不应该高于 session.timeout.ms 的1/3。</td>
</tr>
<tr>
<td>session.timeout.ms</td>
<td><strong>Kafka消费者和coordinator之间连接超时时间，默认45s。超过该值，该消费者被移除，消费者组执行再平衡。</strong></td>
</tr>
<tr>
<td>max.poll.interval.ms</td>
<td>消费者处理消息的最大时长，<strong>默认是5分钟</strong>。<strong>超过该值，该消费者被移除，消费者组执行再平衡。</strong></td>
</tr>
<tr>
<td>partition.assignment.strategy</td>
<td><strong>消费者分区分配策略，默认策略是Range +CooperativeSticky</strong>。Kafka可以同时使用多个分区分配策略。可以选择的策略包括：Range、RoundRobin、Sticky、CooperativeSticky</td>
</tr>
</tbody></table>
<h4 id="Range以及再平衡"><a href="#Range以及再平衡" class="headerlink" title="Range以及再平衡"></a>Range以及再平衡</h4><h5 id="Range分区策略原理"><a href="#Range分区策略原理" class="headerlink" title="Range分区策略原理"></a>Range分区策略原理</h5><p>Range 是对每个topic 而言的。首先对同一个topic 里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。假如现在有7 个分区，3 个消费者，排序后的分区将会是0,1,2,3,4,5,6；消费者排序完之后将会是C0,C1,C2。</p>
<p>通过partitions数/consumer数来决定每个消费者应该消费几个分区。如果除不尽，那么前面几个消费者将会多消费1 个分区。</p>
<p>例如，7/3 = 2 余1 ，除不尽，那么消费者C0 便会多消费1 个分区。8/3=2余2，除不尽，那么C0和C1分别多消费一个。</p>
<p>注意：如果只是针对1 个topic 而言，C0消费者多消费1个分区影响不是很大。但是如果有N 多个topic，那么针对每个topic，消费者C0都将多消费1 个分区，topic越多，C0消费的分区会比其他消费者明显多消费N 个分区。即，多个topic的时候Range分区策略容易产生数据倾斜！</p>
<p><img src="range.png" alt="range"></p>
<h5 id="Range再平衡"><a href="#Range再平衡" class="headerlink" title="Range再平衡"></a>Range再平衡</h5><p>将CustomerConsumer2终止，并查看CustomerConsumer1和CustomerConsumer3的消费情况。</p>
<p>说明：消费者组需要按照超时时间45s来判断它是否退出，所以需要等待，时间到了45s后，判断它真的退出就会把任务分配给其他broker执行。</p>
<p>说明：消费者2已经被踢出消费者组，所以重新按照range方式分配。</p>
<h4 id="RoundRobin以及再平衡"><a href="#RoundRobin以及再平衡" class="headerlink" title="RoundRobin以及再平衡"></a>RoundRobin以及再平衡</h4><p>RoundRobin针对集群中所有Topic而言。RoundRobin轮询分区策略，是把所有的partition 和所有的consumer 都列出来，然后按照hashcode进行排序，最后通过轮询算法来分配partition 给到各个消费者。</p>
<p><img src="%E8%BD%AE%E8%AF%A2.png" alt="轮询"></p>
<h4 id="Sticky以及再平衡"><a href="#Sticky以及再平衡" class="headerlink" title="Sticky以及再平衡"></a>Sticky以及再平衡</h4><p>粘性分区定义：可以理解为分配的结果带有“粘性的”。即在执行一次新的分配之前，考虑上一次分配的结果，尽量少的调整分配的变动，可以节省大量的开销。</p>
<p>粘性分区是Kafka从0.11.x版本开始引入这种分配策略，首先会尽量均衡的放置分区到消费者上面，在出现同一消费者组内消费者出现问题的时候，会尽量保持原有分配的分区不变化。</p>
<h3 id="offset位移"><a href="#offset位移" class="headerlink" title="offset位移"></a>offset位移</h3><h4 id="自动提交"><a href="#自动提交" class="headerlink" title="自动提交"></a>自动提交</h4><p>自动提交offset的相关参数：</p>
<p>enable.auto.commit：是否开启自动提交offset功能，默认是true，消费者会自动周期性地向服务器提交偏移量。。</p>
<p>auto.commit.interval.ms：自动提交offset的时间间隔，默认是5s。如果设置了 enable.auto.commit 的值为true， 则该值定义了消费者偏移量向Kafka提交的频率，默认5s。</p>
<p><img src="offset.png" alt="offset"></p>
<h4 id="手动提交"><a href="#手动提交" class="headerlink" title="手动提交"></a>手动提交</h4><p>为什么要手动提交 offset？</p>
<p>虽然自动提交offset十分简单便利，但由于其是基于时间提交的，开发人员难以把握offset提交的时机。因此Kafka还提供了手动提交offset的API。</p>
<p>手动提交offset的方法有两种：分别是commitSync（同步提交）和commitAsync（异步提交）。两者的相同点是，都会将本次提交的一批数据最高的偏移量提交；不同点是，同步提交阻塞当前线程，一直到提交成功，并且会自动失败重试（由不可控因素导致，也会出现提交失败）；而异步提交则没有失败重试机制，故有可能提交失败。</p>
<p>commitSync（同步提交）：必须等待offset提交完毕，再去消费下一批数据。虽然同步提交offset更可靠一些，但是由于其会阻塞当前线程，直到提交成功。因此吞吐量会受到很大的影响。因此更多的情况下，会选用异步提交offset的方式。</p>
<p>commitAsync（异步提交）：发送完提交offset请求后，就开始消费下一批数据了。</p>
<h4 id="重复消费和漏消费"><a href="#重复消费和漏消费" class="headerlink" title="重复消费和漏消费"></a>重复消费和漏消费</h4><p>重复消费：已经消费了数据，但是offset没提交。 </p>
<p>漏消费：先提交offset后消费，有可能会造成数据的漏消费。</p>
<p><img src="%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%E5%92%8C%E6%BC%8F%E6%B6%88%E8%B4%B9.png" alt="重复消费和漏消费"></p>
<p>如何做到既不漏消费也不重复消费呢？消费者事务</p>
<h4 id="消费者事务"><a href="#消费者事务" class="headerlink" title="消费者事务"></a>消费者事务</h4><p>如果想完成Consumer端的精准一次性消费，那么需要Kafka消费端将消费过程和提交offset过程做原子绑定。</p>
<h4 id="数据积压（消费者如何提高吞吐量）"><a href="#数据积压（消费者如何提高吞吐量）" class="headerlink" title="数据积压（消费者如何提高吞吐量）"></a>数据积压（消费者如何提高吞吐量）</h4><p> 1）如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者数量，消费者数=分区数（两者缺一不可）。</p>
<p> 2）如果是下游的数据处理不及时：提高每批次拉取的数量。批次拉取数据过少（拉取数据/处理时间&lt;生产速度），使处理的数据小于生产的数据，也会造成数据积压。</p>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>fetch.max.bytes</td>
<td><strong>默认Default: 52428800（50 m）</strong>。消费者获取服务器端一批消息最大的字节数。<strong>如果服务器端一批次的数据大于该值（50m）仍然可以拉取回来这批数据，因此，这不是一个绝对最大值。</strong>一批次的大小受message.max.bytes （broker config）or max.message.bytes （topic config）影响。</td>
</tr>
<tr>
<td>max.poll.records</td>
<td>一次poll拉取数据返回消息的最大条数，<strong>默认是500条</strong></td>
</tr>
</tbody></table>
<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><h3 id="Kafka性能高原因"><a href="#Kafka性能高原因" class="headerlink" title="Kafka性能高原因"></a>Kafka性能高原因</h3><ol>
<li>利用了 PageCache 缓存</li>
<li>磁盘顺序写</li>
<li>零拷贝技术</li>
<li>pull 拉模式</li>
</ol>
<h3 id="Kafka-文件高效存储设计原理"><a href="#Kafka-文件高效存储设计原理" class="headerlink" title="Kafka 文件高效存储设计原理"></a>Kafka 文件高效存储设计原理</h3><ol>
<li>Kafka把Topic中一个Partition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完成的文件，减少磁盘占用</li>
<li>通过索引信息可以快速定位Message和确定response的最大大小</li>
<li>通过将索引元数据全部映射到 memory，可以避免 Segment 文件的磁盘I/O操作</li>
<li>通过索引文件稀疏存储，可以大幅降低索引文件元数据占用空间大小</li>
</ol>
<h3 id="Kafka-中分区的概念"><a href="#Kafka-中分区的概念" class="headerlink" title="Kafka 中分区的概念"></a>Kafka 中分区的概念</h3><p>主题是一个逻辑上的概念，还可以细分为多个分区，一个分区只属于单个主题，很多时候也会把分区称为主题分区（Topic-Partition）。同一主题下的不同分区包含的消息是不同的，分区在存储层面可以看做一个可追加的<code>日志文件</code> ，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量（offset）。offset 是消息在分区中的唯一标识，kafka 通过它来保证消息在分区内的顺序性，不过 offset 并不跨越分区，也就是说，kafka保证的是分区有序而不是主题有序。</p>
<p>在分区中又引入了多副本（replica）的概念，通过增加副本数量可以提高容灾能力。同一分区的不同副本中保存的是相同的消息。副本之间是一主多从的关系，其中主副本负责读写，从副本只负责消息同步。副本处于不同的 broker 中，当主副本出现异常，便会在从副本中提升一个为主副本。</p>
<h3 id="Kafka-为什么要把消息分区"><a href="#Kafka-为什么要把消息分区" class="headerlink" title="Kafka 为什么要把消息分区"></a>Kafka 为什么要把消息分区</h3><ol>
<li>方便在集群中扩展，每个 Partition 可用通过调整以适应它所在的机器，而一个Topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了</li>
<li>可以提高并发，因为可以以Partition为单位进行读写</li>
</ol>
<h3 id="Kafka-消息的消费模式"><a href="#Kafka-消息的消费模式" class="headerlink" title="Kafka 消息的消费模式"></a>Kafka 消息的消费模式</h3><p>如果采用 <strong>Push</strong> 模式，则Consumer难以处理不同速率的上游推送消息。</p>
<p>采用 Pull 模式的好处是Consumer可以自主决定是否批量的从Broker拉取数据。Pull模式有个缺点是，如果Broker没有可供消费的消息，将导致Consumer不断在循环中轮询，直到新消息到达。为了避免这点，Kafka有个参数可以让Consumer阻塞直到新消息到达。</p>
<h3 id="Kafka-如何实现负载均衡与故障转移"><a href="#Kafka-如何实现负载均衡与故障转移" class="headerlink" title="Kafka 如何实现负载均衡与故障转移"></a>Kafka 如何实现负载均衡与故障转移</h3><p><strong>负载均衡</strong></p>
<p>Kakfa 的负载均衡就是每个 <strong>Broker</strong> 都有均等的机会为 Kafka 的客户端（生产者与消费者）提供服务，可以负载分散到所有集群中的机器上。Kafka 通过智能化的分区领导者选举来实现负载均衡，提供智能化的 Leader 选举算法，可在集群的所有机器上均匀分散各个Partition的Leader，从而整体上实现负载均衡。</p>
<p><strong>故障转移</strong></p>
<p>Kafka 的故障转移是通过使用<strong>会话机制</strong>实现的，每台 Kafka 服务器启动后会以会话的形式把自己注册到 Zookeeper 服务器上。一旦服务器运转出现问题，就会导致与Zookeeper 的会话不能维持从而超时断连，此时Kafka集群会选举出另一台服务器来完全替代这台服务器继续提供服务。</p>
<h3 id="Kafka-的Topic中-Partition-数据是怎么存储到磁盘的"><a href="#Kafka-的Topic中-Partition-数据是怎么存储到磁盘的" class="headerlink" title="Kafka 的Topic中 Partition 数据是怎么存储到磁盘的"></a>Kafka 的Topic中 Partition 数据是怎么存储到磁盘的</h3><p>Topic 中的多个 Partition 以文件夹的形式保存到 Broker，每个分区序号从0递增，且消息有序。Partition 文件下有多个Segment（xxx.index，xxx.log），Segment文件里的大小和配置文件大小一致。默认为1GB，但可以根据实际需要修改。如果大小大于1GB时，会滚动一个新的Segment并且以上一个Segment最后一条消息的偏移量命名。</p>
<h3 id="Kafka-创建Topic后如何将分区放置到不同的-Broker-中"><a href="#Kafka-创建Topic后如何将分区放置到不同的-Broker-中" class="headerlink" title="Kafka 创建Topic后如何将分区放置到不同的 Broker 中"></a>Kafka 创建Topic后如何将分区放置到不同的 Broker 中</h3><p>Kafka创建Topic将分区放置到不同的Broker时遵循以下规则：</p>
<ol>
<li>副本因子不能大于Broker的个数。</li>
<li>第一个分区（编号为0）的第一个副本放置位置是随机从Broker List中选择的。</li>
<li>其他分区的第一个副本放置位置相对于第0个分区依次往后移。也就是如果有3个Broker，3个分区，假设第一个分区放在第二个Broker上，那么第二个分区将会放在第三个Broker上；第三个分区将会放在第一个Broker上，更多Broker与更多分区依此类推。剩余的副本相对于第一个副本放置位置其实是由<code>nextReplicaShift</code>决定的，而这个数也是随机产生的。</li>
</ol>
<h3 id="Kafka-的日志保留期与数据清理策略"><a href="#Kafka-的日志保留期与数据清理策略" class="headerlink" title="Kafka 的日志保留期与数据清理策略"></a>Kafka 的日志保留期与数据清理策略</h3><p><strong>概念</strong></p>
<p>保留期内保留了Kafka群集中的所有已发布消息，超过保期的数据将被按清理策略进行清理。默认保留时间是7天，如果想修改时间，在<code>server.properties</code>里更改参数<code>log.retention.hours/minutes/ms</code> 的值便可。</p>
<p><strong>清理策略</strong></p>
<ul>
<li><strong>删除：</strong> <code>log.cleanup.policy=delete</code> 表示启用删除策略，这也是默认策略。一开始只是标记为delete，文件无法被索引。只有过了<code>log.Segment.delete.delay.ms</code>这个参数设置的时间，才会真正被删除。</li>
<li><strong>压缩：</strong> <code>log.cleanup.policy=compact</code> 表示启用压缩策略，将数据压缩，只保留每个Key最后一个版本的数据。首先在Broker的配置中设置<code>log.cleaner.enable=true</code> 启用 cleaner，这个默认是关闭的。</li>
</ul>
<h3 id="Kafka-中什么情况下会出现消息丢失-不一致的问题"><a href="#Kafka-中什么情况下会出现消息丢失-不一致的问题" class="headerlink" title="Kafka 中什么情况下会出现消息丢失/不一致的问题"></a>Kafka 中什么情况下会出现消息丢失/不一致的问题</h3><p><strong>消息发送时</strong></p>
<p>消息发送有两种方式：<code>同步 - sync</code> 和 <code>异步 - async</code>。默认是同步的方式，可以通过 producer.type 属性进行配置，kafka 也可以通过配置 acks 属性来确认消息的生产</p>
<ul>
<li><code>0</code>：表示不进行消息接收是否成功的确认</li>
<li><code>1</code>：表示当 leader 接收成功时的确认</li>
<li><code>-1</code>：表示 leader 和 follower 都接收成功的确认</li>
</ul>
<p>当 acks = 0 时，不和 Kafka 进行消息接收确认，可能会因为网络异常，缓冲区满的问题，导致消息丢失</p>
<p>当 acks = 1 时，只有 leader 同步成功而 follower 尚未完成同步，如果 leader 挂了，就会造成数据丢失</p>
<p><strong>消息消费时</strong></p>
<p>Kafka 有两个消息消费的 consumer 接口，分别是 <code>low-level</code> 和 <code>hign-level</code></p>
<ol>
<li><code>low-level</code>：消费者自己维护 offset 等值，可以实现对 kafka 的完全控制</li>
<li><code>high-level</code>：封装了对 partition 和 offset，使用简单</li>
</ol>
<p>如果使用高级接口，可能存在一个消费者提取了一个消息后便提交了 offset，那么还没来得及消费就已经挂了，下次消费时的数据就是 offset + 1 的位置，那么原先 offset 的数据就丢失了。</p>
<h3 id="Kafka-中如何保证顺序消费"><a href="#Kafka-中如何保证顺序消费" class="headerlink" title="Kafka 中如何保证顺序消费"></a>Kafka 中如何保证顺序消费</h3><p>Kafka 的消费单元是 Partition，同一个 Partition 使用 offset 作为唯一标识保证顺序性，但这只是保证了在 Partition 内部的顺序性而不是 Topic 中的顺序，因此我们需要将所有消息发往统一 Partition 才能保证消息顺序消费，那么可以在发送的时候指定 MessageKey，同一个 key 的消息会发到同一个 Partition 中。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Kafka/" rel="tag"># Kafka</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/04/22/Goroutine/" rel="prev" title="Goroutine">
      <i class="fa fa-chevron-left"></i> Goroutine
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/04/22/Raft/" rel="next" title="Raft">
      Raft <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Kafka"><span class="nav-number">1.</span> <span class="nav-text">Kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#简介"><span class="nav-number">1.1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基本概念"><span class="nav-number">1.2.</span> <span class="nav-text">基本概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#定义"><span class="nav-number">1.2.1.</span> <span class="nav-text">定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#消息队列"><span class="nav-number">1.2.2.</span> <span class="nav-text">消息队列</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#传统消息队列的应用场景"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">传统消息队列的应用场景</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#两种模式"><span class="nav-number">1.2.2.2.</span> <span class="nav-text">两种模式</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#点对点模式"><span class="nav-number">1.2.2.2.1.</span> <span class="nav-text">点对点模式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#发布-订阅模式"><span class="nav-number">1.2.2.2.2.</span> <span class="nav-text">发布-订阅模式</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基础架构"><span class="nav-number">1.2.3.</span> <span class="nav-text">基础架构</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#生产者"><span class="nav-number">1.3.</span> <span class="nav-text">生产者</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#消息发送流程"><span class="nav-number">1.3.1.</span> <span class="nav-text">消息发送流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#参数列表"><span class="nav-number">1.3.2.</span> <span class="nav-text">参数列表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分区"><span class="nav-number">1.3.3.</span> <span class="nav-text">分区</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#分区好处"><span class="nav-number">1.3.3.1.</span> <span class="nav-text">分区好处</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#分区策略"><span class="nav-number">1.3.3.2.</span> <span class="nav-text">分区策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#提高生产者吞吐量"><span class="nav-number">1.3.3.3.</span> <span class="nav-text">提高生产者吞吐量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#提高数据可靠性"><span class="nav-number">1.3.3.4.</span> <span class="nav-text">提高数据可靠性</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#ACK"><span class="nav-number">1.3.3.4.1.</span> <span class="nav-text">ACK</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#总结"><span class="nav-number">1.3.3.4.2.</span> <span class="nav-text">总结</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据去重"><span class="nav-number">1.3.4.</span> <span class="nav-text">数据去重</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#传递语义"><span class="nav-number">1.3.4.1.</span> <span class="nav-text">传递语义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#幂等"><span class="nav-number">1.3.4.2.</span> <span class="nav-text">幂等</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#生产者事务"><span class="nav-number">1.3.4.3.</span> <span class="nav-text">生产者事务</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据有序"><span class="nav-number">1.3.5.</span> <span class="nav-text">数据有序</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#broker"><span class="nav-number">1.4.</span> <span class="nav-text">broker</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#broker工作流程"><span class="nav-number">1.4.1.</span> <span class="nav-text">broker工作流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#参数"><span class="nav-number">1.4.2.</span> <span class="nav-text">参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#副本"><span class="nav-number">1.4.3.</span> <span class="nav-text">副本</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Kafka副本"><span class="nav-number">1.4.3.1.</span> <span class="nav-text">Kafka副本</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Leader选举"><span class="nav-number">1.4.3.2.</span> <span class="nav-text">Leader选举</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Leader和Follower故障处理细节"><span class="nav-number">1.4.3.3.</span> <span class="nav-text">Leader和Follower故障处理细节</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#文件存储"><span class="nav-number">1.4.4.</span> <span class="nav-text">文件存储</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#文件存储机制"><span class="nav-number">1.4.4.1.</span> <span class="nav-text">文件存储机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#文件清理策略"><span class="nav-number">1.4.4.2.</span> <span class="nav-text">文件清理策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#高效读写数据"><span class="nav-number">1.4.4.3.</span> <span class="nav-text">高效读写数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PageCache-零拷贝"><span class="nav-number">1.4.4.4.</span> <span class="nav-text">PageCache+零拷贝</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#消费者"><span class="nav-number">1.5.</span> <span class="nav-text">消费者</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka消费方式"><span class="nav-number">1.5.1.</span> <span class="nav-text">Kafka消费方式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#拉"><span class="nav-number">1.5.1.1.</span> <span class="nav-text">拉</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#推"><span class="nav-number">1.5.1.2.</span> <span class="nav-text">推</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#工作流程"><span class="nav-number">1.5.2.</span> <span class="nav-text">工作流程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#消费者组"><span class="nav-number">1.5.2.1.</span> <span class="nav-text">消费者组</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#初始化"><span class="nav-number">1.5.2.2.</span> <span class="nav-text">初始化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#消费流程"><span class="nav-number">1.5.2.3.</span> <span class="nav-text">消费流程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#消费者参数"><span class="nav-number">1.5.3.</span> <span class="nav-text">消费者参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分区平衡以及再平衡"><span class="nav-number">1.5.4.</span> <span class="nav-text">分区平衡以及再平衡</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Range以及再平衡"><span class="nav-number">1.5.4.1.</span> <span class="nav-text">Range以及再平衡</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Range分区策略原理"><span class="nav-number">1.5.4.1.1.</span> <span class="nav-text">Range分区策略原理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Range再平衡"><span class="nav-number">1.5.4.1.2.</span> <span class="nav-text">Range再平衡</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RoundRobin以及再平衡"><span class="nav-number">1.5.4.2.</span> <span class="nav-text">RoundRobin以及再平衡</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sticky以及再平衡"><span class="nav-number">1.5.4.3.</span> <span class="nav-text">Sticky以及再平衡</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#offset位移"><span class="nav-number">1.5.5.</span> <span class="nav-text">offset位移</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#自动提交"><span class="nav-number">1.5.5.1.</span> <span class="nav-text">自动提交</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#手动提交"><span class="nav-number">1.5.5.2.</span> <span class="nav-text">手动提交</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#重复消费和漏消费"><span class="nav-number">1.5.5.3.</span> <span class="nav-text">重复消费和漏消费</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#消费者事务"><span class="nav-number">1.5.5.4.</span> <span class="nav-text">消费者事务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数据积压（消费者如何提高吞吐量）"><span class="nav-number">1.5.5.5.</span> <span class="nav-text">数据积压（消费者如何提高吞吐量）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题"><span class="nav-number">1.6.</span> <span class="nav-text">面试题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka性能高原因"><span class="nav-number">1.6.1.</span> <span class="nav-text">Kafka性能高原因</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-文件高效存储设计原理"><span class="nav-number">1.6.2.</span> <span class="nav-text">Kafka 文件高效存储设计原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-中分区的概念"><span class="nav-number">1.6.3.</span> <span class="nav-text">Kafka 中分区的概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-为什么要把消息分区"><span class="nav-number">1.6.4.</span> <span class="nav-text">Kafka 为什么要把消息分区</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-消息的消费模式"><span class="nav-number">1.6.5.</span> <span class="nav-text">Kafka 消息的消费模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-如何实现负载均衡与故障转移"><span class="nav-number">1.6.6.</span> <span class="nav-text">Kafka 如何实现负载均衡与故障转移</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-的Topic中-Partition-数据是怎么存储到磁盘的"><span class="nav-number">1.6.7.</span> <span class="nav-text">Kafka 的Topic中 Partition 数据是怎么存储到磁盘的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-创建Topic后如何将分区放置到不同的-Broker-中"><span class="nav-number">1.6.8.</span> <span class="nav-text">Kafka 创建Topic后如何将分区放置到不同的 Broker 中</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-的日志保留期与数据清理策略"><span class="nav-number">1.6.9.</span> <span class="nav-text">Kafka 的日志保留期与数据清理策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-中什么情况下会出现消息丢失-不一致的问题"><span class="nav-number">1.6.10.</span> <span class="nav-text">Kafka 中什么情况下会出现消息丢失&#x2F;不一致的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-中如何保证顺序消费"><span class="nav-number">1.6.11.</span> <span class="nav-text">Kafka 中如何保证顺序消费</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <a href="/">
      <img class="site-author-image" itemprop="image" alt="Charispsychoma"
        src="/images/avatar.jpg">
    </a>
  <p class="site-author-name" itemprop="name">Charispsychoma</p>
  <div class="site-description" itemprop="description">Stay hungry. Stay foolish.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">50</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">37</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">42</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/IRVLIN" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;IRVLIN" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:irvlin0404@gmail.com" title="E-Mail → mailto:irvlin0404@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/charispsychoma" title="Zhihu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;charispsychoma" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i>Zhihu</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.instagram.com/irv.lin/" title="Instagram → https:&#x2F;&#x2F;www.instagram.com&#x2F;irv.lin&#x2F;" rel="noopener" target="_blank"><i class="fab fa-instagram fa-fw"></i>Instagram</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
<script>
    var now = new Date(); 
    function createtime() { 
        var grt= new Date("05/11/2020 14:44:44");//在此处修改你的建站时间
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = "已存活 "+dnum+" 天 "; 
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; 
    } 
setInterval("createtime()",250);
</script>

<div class="copyright">
  
  &copy; 2020 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Charispsychoma</span>
</div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
         访客数: <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        访问量: <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'BTYxjkQrcW0LVlgoggIJ2kD4-gzGzoHsz',
      appKey     : 'JJRnAk74iYw1AJ5GBVnXaT6b',
      placeholder: "欢迎评论～",
      avatar     : 'retro',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

    </div>

  <!-- require APlayer -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css">
  <script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script>
  <!-- require MetingJS -->
  <script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

  <meting-js
    server="netease" type="playlist" id="574119204" order="random" volume=0.5 fixed=true theme="#333">
  </meting-js>

  <script type="text/javascript" src="/js/clicklove.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/irvlin/CDN/js/jquery-3.4.1.min.js"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/00years/ribbon@v1.0/ribbon.min.js"></script>
  <script src="/live2d-widget/autoload.js"></script>
</body>
</html>
