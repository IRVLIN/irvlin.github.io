<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-128x128.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-64x64.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-center-simple.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"irvlin.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"default"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Redis详解">
<meta property="og:type" content="article">
<meta property="og:title" content="Redis">
<meta property="og:url" content="https://irvlin.github.io/2024/04/22/Redis/index.html">
<meta property="og:site_name" content="IRvLin的博客">
<meta property="og:description" content="Redis详解">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/redis%E7%AE%80%E4%BB%8B.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%842.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/%E5%AE%9E%E7%8E%B0.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/bloomFilter.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/stream.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/stream2.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/%E5%8D%95%E7%BA%BF%E7%A8%8B.jpg">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%BC%8F.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/AOF.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/AOF2.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/AOF3.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/AOF4.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/AOF5.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/RDB.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/RDB2.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/%E6%B7%B7%E5%90%88%E6%8C%81%E4%B9%85%E5%8C%96.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4.jpg">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/%E6%83%B0%E6%80%A7%E5%88%A0%E9%99%A4.jpg">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/%E5%AE%9A%E6%9C%9F%E5%88%A0%E9%99%A4.jpg">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/cache-aside.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/cache-aside2.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/cache-aside3.png">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/read-write-through.jpg">
<meta property="og:image" content="https://irvlin.github.io/2024/04/22/Redis/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.jpg">
<meta property="article:published_time" content="2024-04-21T17:00:40.000Z">
<meta property="article:modified_time" content="2024-04-22T13:42:52.746Z">
<meta property="article:author" content="Charispsychoma">
<meta property="article:tag" content="redis">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://irvlin.github.io/2024/04/22/Redis/redis%E7%AE%80%E4%BB%8B.png">

<link rel="canonical" href="https://irvlin.github.io/2024/04/22/Redis/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Redis | IRvLin的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">IRvLin的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger">
            <i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    

  <a href="https://github.com/irvlin" class="github-corner" title="Fork me on GitHub" aria-label="Fork me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://irvlin.github.io/2024/04/22/Redis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Charispsychoma">
      <meta itemprop="description" content="Stay hungry. Stay foolish.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="IRvLin的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Redis
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2024-04-22 01:00:40 / 修改时间：21:42:52" itemprop="dateCreated datePublished" datetime="2024-04-22T01:00:40+08:00">2024-04-22</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/redis/" itemprop="url" rel="index"><span itemprop="name">redis</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2024/04/22/Redis/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/04/22/Redis/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Redis详解</p>
<a id="more"></a>

<h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><img src="redis%E7%AE%80%E4%BB%8B.png" alt="redis简介"></p>
<p>Redis是一种基于键值对（key-value）的NoSQL数据库。</p>
<p>比一般键值对数据库强大的地方，Redis中的value支持string（字符串）、hash（哈希）、 list（列表）、set（集合）、zset（有序集合）、Bitmaps（位图）、 HyperLogLog、GEO（地理信息定位）等多种数据结构，因此 Redis可以满足很多的应用场景。并且对数据类型的操作都是<strong>原子性</strong>的，因为执行命令由单线程负责的，不存在并发竞争的问题。</p>
<p>Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此<strong>读写速度非常快</strong>，常用于<strong>缓存，消息队列、分布式锁等场景</strong>。</p>
<p>不仅如此，Redis还可以将内存的数据利用快照和日志的形式保存到硬盘上，这样在发生类似断电或者机器故障的时候，内存中的数据不会“丢失”。</p>
<p>除此之外，Redis 还支持<strong>事务 、持久化、Lua 脚本、多种集群方案（主从复制模式、哨兵模式、切片机群模式）、发布/订阅模式，内存淘汰机制、过期删除机制</strong>等等。</p>
<p>总之，Redis是一款强大的性能利器。</p>
<h2 id="Redis-和-Memcached-的区别"><a href="#Redis-和-Memcached-的区别" class="headerlink" title="Redis 和 Memcached 的区别"></a>Redis 和 Memcached 的区别</h2><p>很多人都说用 Redis 作为缓存，但是 Memcached 也是基于内存的数据库，为什么不选择它作为缓存呢？要解答这个问题，我们就要弄清楚 Redis 和 Memcached 的区别。 Redis 与 Memcached <strong>共同点</strong>：</p>
<ol>
<li>都是基于内存的数据库，一般都用来当做缓存使用。</li>
<li>都有过期策略。</li>
<li>两者的性能都非常高。</li>
</ol>
<p>Redis 与 Memcached 区别：</p>
<ul>
<li>Redis 支持的数据类型更丰富（String、Hash、List、Set、ZSet），而 Memcached 只支持最简单的 key-value 数据类型；</li>
<li>Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 没有持久化功能，数据全部存在内存之中，Memcached 重启或者挂掉后，数据就没了；</li>
<li>Redis 原生支持集群模式，Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；</li>
<li>Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持；</li>
</ul>
<h2 id="数据结构、使用场景"><a href="#数据结构、使用场景" class="headerlink" title="数据结构、使用场景"></a>数据结构、使用场景</h2><p>Redis 提供了丰富的数据类型，常见的有五种数据类型：<strong>String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）</strong>。</p>
<p><img src="%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="数据结构"></p>
<p><img src="%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%842.png" alt="数据结构"></p>
<p>随着 Redis 版本的更新，后面又支持了四种数据类型： <strong>BitMap（2.2 版新增）、HyperLogLog（2.8 版新增）、GEO（3.2 版新增）、Stream（5.0 版新增）</strong>。 Redis 五种数据类型的应用场景：</p>
<ul>
<li>String 类型的应用场景：缓存对象、常规计数、分布式锁、共享 session 信息等。</li>
<li>List 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。</li>
<li>Hash 类型：缓存对象、购物车等。</li>
<li>Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。</li>
<li>Zset 类型：排序场景，比如排行榜、电话和姓名排序等。</li>
</ul>
<p>Redis 后续版本又支持四种数据类型，它们的应用场景如下：</p>
<ul>
<li>BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；</li>
<li>HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；</li>
<li>GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；</li>
<li>Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。</li>
</ul>
<h3 id="热点数据的缓存"><a href="#热点数据的缓存" class="headerlink" title="热点数据的缓存"></a>热点数据的缓存</h3><p>缓存是Redis最常见的应用场景，之所有这么使用，主要是因为Redis读写性能优异。而且逐渐有取代memcached，成为首选服务端缓存的组件。而且，Redis内部是支持事务的，在使用时候能有效保证数据的一致性。</p>
<p>作为缓存使用时，一般有两种方式保存数据：</p>
<ul>
<li>读取前，先去读Redis，如果没有数据，读取数据库，将数据拉入Redis。</li>
<li>插入数据时，同时写入Redis。</li>
</ul>
<p>方案一：实施起来简单，但是有两个需要注意的地方：</p>
<ul>
<li>避免缓存击穿。（数据库没有就需要命中的数据，导致Redis一直没有数据，而一直命中数据库。）</li>
<li>数据的实时性相对会差一点。</li>
</ul>
<p>方案二：数据实时性强，但是开发时不便于统一处理。</p>
<p>当然，两种方式根据实际情况来适用。如：方案一适用于对于数据实时性要求不是特别高的场景。方案二适用于字典表、数据量不大的数据存储。</p>
<h3 id="限时业务的运用"><a href="#限时业务的运用" class="headerlink" title="限时业务的运用"></a>限时业务的运用</h3><p>redis中可以使用expire命令设置一个键的生存时间，到时间后redis会删除它。利用这一特性可以运用在限时的优惠活动信息、手机验证码等业务场景。</p>
<h3 id="计数器相关问题"><a href="#计数器相关问题" class="headerlink" title="计数器相关问题"></a>计数器相关问题</h3><p>redis由于incrby命令可以实现原子性的递增，所以可以运用于高并发的秒杀活动、分布式序列号的生成、具体业务还体现在比如限制一个手机号发多少条短信、一个接口一分钟限制多少请求、一个接口一天限制调用多少次等等。</p>
<h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><p>这个主要利用redis的setnx命令进行，setnx：”set if not exists”就是如果不存在则成功设置缓存同时返回1，否则返回0 ，这个特性在很多后台中都有所运用，因为我们服务器是集群的，定时任务可能在两台机器上都会运行，所以在定时任务中首先 通过setnx设置一个lock， 如果成功设置则执行，如果没有成功设置，则表明该定时任务已执行。 当然结合具体业务，我们可以给这个lock加一个过期时间，比如说30分钟执行一次的定时任务，那么这个过期时间设置为小于30分钟的一个时间就可以，这个与定时任务的周期以及定时任务执行消耗时间相关。</p>
<p>在分布式锁的场景中，主要用在比如秒杀系统等。</p>
<h3 id="延时操作"><a href="#延时操作" class="headerlink" title="延时操作"></a>延时操作</h3><p>比如在订单生产后我们占用了库存，10分钟后去检验用户是否真正购买，如果没有购买将该单据设置无效，同时还原库存。 由于redis自2.8.0之后版本提供Keyspace Notifications功能，允许客户订阅Pub/Sub频道，以便以某种方式接收影响Redis数据集的事件。 所以我们对于上面的需求就可以用以下解决方案，我们在订单生产时，设置一个key，同时设置10分钟后过期， 我们在后台实现一个监听器，监听key的实效，监听到key失效时将后续逻辑加上。</p>
<p>当然我们也可以利用rabbitmq、activemq等消息中间件的延迟队列服务实现该需求。</p>
<h3 id="排行榜相关问题"><a href="#排行榜相关问题" class="headerlink" title="排行榜相关问题"></a>排行榜相关问题</h3><p>关系型数据库在排行榜方面查询速度普遍偏慢，所以可以借助redis的SortedSet进行热点数据的排序。</p>
<p>比如点赞排行榜，做一个SortedSet, 然后以用户的openid作为上面的username, 以用户的点赞数作为上面的score, 然后针对每个用户做一个hash, 通过zrangebyscore就可以按照点赞数获取排行榜，然后再根据username获取用户的hash信息，这个当时在实际运用中性能体验也蛮不错的。</p>
<h3 id="点赞、好友等相互关系的存储"><a href="#点赞、好友等相互关系的存储" class="headerlink" title="点赞、好友等相互关系的存储"></a>点赞、好友等相互关系的存储</h3><p>Redis 利用集合的一些命令，比如求交集、并集、差集等。</p>
<p>在微博应用中，每个用户关注的人存在一个集合中，就很容易实现求两个人的共同好友功能。</p>
<h3 id="简单队列"><a href="#简单队列" class="headerlink" title="简单队列"></a>简单队列</h3><p>由于Redis有list push和list pop这样的命令，所以能够很方便的执行队列操作。</p>
<h3 id="结构实现"><a href="#结构实现" class="headerlink" title="结构实现"></a>结构实现</h3><p><img src="%E5%AE%9E%E7%8E%B0.png" alt="实现"></p>
<h4 id="String"><a href="#String" class="headerlink" title="String"></a>String</h4><p>String 类型的底层的数据结构实现主要是 SDS（简单动态字符串）。 SDS 和我们认识的 C 字符串不太一样，之所以没有使用 C 语言的字符串表示，因为 SDS 相比于 C 的原生字符串：</p>
<ul>
<li><strong>SDS 不仅可以保存文本数据，还可以保存二进制数据</strong>。因为 SDS 使用 len 属性的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 buf[] 数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。</li>
<li><strong>SDS 获取字符串长度的时间复杂度是 O(1)</strong>。因为 C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n)；而 SDS 结构里用 len 属性记录了字符串长度，所以复杂度为 O(1)。</li>
<li><strong>Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出</strong>。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。</li>
</ul>
<h4 id="List"><a href="#List" class="headerlink" title="List"></a>List</h4><p>List 类型的底层数据结构是由<strong>双向链表或压缩列表</strong>实现的：</p>
<ul>
<li>如果列表的元素个数小于 512 个（默认值，可由 list-max-ziplist-entries 配置），列表每个元素的值都小于 64 字节（默认值，可由 list-max-ziplist-value 配置），Redis 会使用<strong>压缩列表</strong>作为 List 类型的底层数据结构；</li>
<li>如果列表的元素不满足上面的条件，Redis 会使用<strong>双向链表</strong>作为 List 类型的底层数据结构；</li>
</ul>
<p>但是<strong>在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表</strong>。</p>
<h4 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h4><p>Hash 类型的底层数据结构是由<strong>压缩列表或哈希表</strong>实现的：</p>
<ul>
<li>如果哈希类型元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用<strong>压缩列表</strong>作为 Hash 类型的底层数据结构；</li>
<li>如果哈希类型元素不满足上面条件，Redis 会使用<strong>哈希表</strong>作为 Hash 类型的底层数据结构。</li>
</ul>
<p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了</strong>。</p>
<h4 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h4><p>Set 类型的底层数据结构是由<strong>哈希表或整数集合</strong>实现的：</p>
<ul>
<li>如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用<strong>整数集合</strong>作为 Set 类型的底层数据结构；</li>
<li>如果集合中的元素不满足上面条件，则 Redis 使用<strong>哈希表</strong>作为 Set 类型的底层数据结构。</li>
</ul>
<h4 id="ZSet"><a href="#ZSet" class="headerlink" title="ZSet"></a>ZSet</h4><p>Zset 类型的底层数据结构是由<strong>压缩列表或跳表</strong>实现的：</p>
<ul>
<li>如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用<strong>压缩列表</strong>作为 Zset 类型的底层数据结构；</li>
<li>如果有序集合的元素不满足上面的条件，Redis 会使用<strong>跳表</strong>作为 Zset 类型的底层数据结构；</li>
</ul>
<p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。</strong></p>
<h4 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h4><p>Redis 2.8.9 版本更新了 Hyperloglog 数据结构</p>
<p>这个结构可以非常省内存的去统计各种计数，比如注册 IP 数、每日访问 IP 数、页面实时UV、在线用户数，共同好友数等。</p>
<p>一个大型的网站，每天 IP 比如有 100 万，粗算一个 IP 消耗 15 字节，那么 100 万个 IP 就是 15M。而 HyperLogLog 在 Redis 中每个键占用的内容都是 12K，理论存储近似接近 2^64 个值，不管存储的内容是什么，它一个基于基数估算的算法，只能比较准确的估算出基数，可以使用少量固定的内存去存储并识别集合中的唯一元素。而且这个估算的基数并不一定准确，是一个带有 0.81% 标准错误的近似值（对于可以接受一定容错的业务场景，比如IP数统计，UV等，是可以忽略不计的）。</p>
<h4 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h4><p>如果想要判断一个元素是不是在一个集合里，一般想到的是将所有元素保存起来，然后通过比较确定。 链表，树等等数据结构都是这种思路. 但是随着集合中元素的增加，我们需要的存储空间越来越大， 检索速度也越来越慢(O(n),O(logn))。</p>
<p>不过还有一种叫作散列表(又叫哈希表，Hash table)的数据结构，它可以通过一个Hash函数将一个 元素映射成一个位阵列中的一个点，这样一来，我们只要看看这个点是不是1就可以知道集合中有没有它了。 这就是布隆过滤器的基本思想。</p>
<p>布隆过滤器实际上是一个很长的二进制向量和一系列随机映射函数 ，实际上你也可以把它简单理解为一个不怎么精确的 set 结构，当你使用它的 contains 方法判断某个对象是否存在时，它可能会误判。但是布隆过滤器也不是特别不精确，只要参数设置的合理， 它的精确度可以控制的相对足够精确，只会有小小的误判概率。</p>
<p>当布隆过滤器说某个值存在时，这个值<strong>可能</strong>不存在；当它说不存在时，那么<strong>一定</strong>不存在。</p>
<p><img src="bloomFilter.png" alt="bloomFilter"></p>
<p>以上图为例，集合里有 x、y、z 三个元素，哈希函数的个数为3。首先初始化位数组，将元素全部置为0。对于 x、y、z 三个元素挨个通过3个哈希函数进行映射，每个映射都会生成一个哈希值，对应位数组上的一个位置，将这个位置的值置为1。对于要查询的元素w，同样通过这3个哈希函数获取映射，依次与位数组上对应位置的值进行比较，如果都为1，布隆过滤器则判定w存在于集合中，否则则不存在。可以看出，布隆过滤器并不能准确判定一个元素是否存在于集合中，因为位数组某个位置上的值为1，也有可能是其他元素通过哈希函数设置的；但很明显布隆过滤器可以准确判定一个元素不存在于集合中。</p>
<h4 id="bitmap"><a href="#bitmap" class="headerlink" title="bitmap"></a>bitmap</h4><p>Bitmap 即位图数据结构，都是操作二进制位来进行记录，只有0 和 1 两个状态。</p>
<p>用来解决什么问题？</p>
<p>比如：统计用户信息，活跃，不活跃！ 登录，未登录！ 打卡，不打卡！ <strong>两个状态的，都可以使用 Bitmaps</strong>！</p>
<p>如果存储一年的打卡状态需要多少内存呢？ 365 天 = 365 bit 1字节 = 8bit 46 个字节左右！</p>
<h4 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h4><p>Redis Stream 是 Redis 5.0 版本新增加的数据类型，Redis 专门为消息队列设计的数据类型。</p>
<p>在 Redis 5.0 Stream 没出来之前，消息队列的实现方式都有着各自的缺陷，例如：</p>
<ul>
<li>发布订阅模式，不能持久化也就无法可靠的保存消息，并且对于离线重连的客户端不能读取历史消息的缺陷；</li>
<li>List 实现消息队列的方式不能重复消费，一个消息消费完就会被删除，而且生产者需要自行实现全局唯一 ID。</li>
</ul>
<p>基于以上问题，Redis 5.0 便推出了 Stream 类型也是此版本最重要的功能，用于完美地实现消息队列，它支持消息的持久化、支持自动生成全局唯一 ID、支持 ack 确认消息的模式、支持消费组模式等，让消息队列更加的稳定和可靠。</p>
<p><strong>基于 Stream 实现的消息队列，如何保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息？</strong></p>
<p>Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知 Streams“消息已经处理完成”。</p>
<p>消费确认增加了消息的可靠性，一般在业务处理完成之后，需要执行 XACK 命令确认消息已经被消费完成，整个流程的执行如下图所示：</p>
<p><img src="stream.png" alt="stream"></p>
<p>如果消费者没有成功处理消息，它就不会给 Streams 发送 XACK 命令，消息仍然会留存。此时，<strong>消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息</strong>。</p>
<p><strong>Redis 基于 Stream 消息队列与专业的消息队列有哪些差距？</strong></p>
<p>一个专业的消息队列，必须要做到两大块：</p>
<ul>
<li>消息不丢。</li>
<li>消息可堆积。</li>
</ul>
<p><strong>Redis Stream 消息会丢失吗？</strong></p>
<p>使用一个消息队列，其实就分为三大块：<strong>生产者、队列中间件、消费者</strong>，所以要保证消息就是保证三个环节都不能丢失数据。</p>
<p><img src="stream2.png" alt="stream"></p>
<p>Redis Stream 消息队列能不能保证三个环节都不丢失数据？</p>
<ul>
<li><p>Redis 生产者会不会丢消息？生产者会不会丢消息，取决于生产者对于异常情况的处理是否合理。 从消息被生产出来，然后提交给 MQ 的过程中，只要能正常收到 （ MQ 中间件） 的 ack 确认响应，就表示发送成功，所以只要处理好返回值和异常，如果返回异常则进行消息重发，那么这个阶段是不会出现消息丢失的。</p>
</li>
<li><p>Redis 消费者会不会丢消息？不会，因为 Stream （ MQ 中间件）会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，但是未被确认的消息。消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。等到消费者执行完业务逻辑后，再发送消费确认 XACK 命令，也能保证消息的不丢失。</p>
</li>
<li><p>Redis 消息中间件会不会丢消息？</p>
<p>会，Redis 在以下 2 个场景下，都会导致数据丢失：</p>
<ul>
<li>AOF 持久化配置为每秒写盘，但这个写盘过程是异步的，Redis 宕机时会存在数据丢失的可能</li>
<li>主从复制也是异步的，<a href="https://xiaolincoding.com/redis/cluster/master_slave_replication.html#redis-主从切换如何减少数据丢失" target="_blank" rel="noopener">主从切换时，也存在丢失数据的可能 (opens new window)</a>。</li>
</ul>
</li>
</ul>
<p>可以看到，Redis 在队列中间件环节无法保证消息不丢。像 RabbitMQ 或 Kafka 这类专业的队列中间件，在使用时是部署一个集群，生产者在发布消息时，队列中间件通常会写「多个节点」，也就是有多个副本，这样一来，即便其中一个节点挂了，也能保证集群的数据不丢失。</p>
<p><strong>Redis Stream 消息可堆积吗？</strong></p>
<p>Redis 的数据都存储在内存中，这就意味着一旦发生消息积压，则会导致 Redis 的内存持续增长，如果超过机器内存上限，就会面临被 OOM 的风险。</p>
<p>所以 Redis 的 Stream 提供了可以指定队列最大长度的功能，就是为了避免这种情况发生。</p>
<p>当指定队列最大长度时，队列长度超过上限后，旧消息会被删除，只保留固定长度的新消息。这么来看，Stream 在消息积压时，如果指定了最大长度，还是有可能丢失消息的。</p>
<p>但 Kafka、RabbitMQ 专业的消息队列它们的数据都是存储在磁盘上，当消息积压时，无非就是多占用一些磁盘空间。</p>
<p>因此，把 Redis 当作队列来使用时，会面临的 2 个问题：</p>
<ul>
<li>Redis 本身可能会丢数据；</li>
<li>面对消息挤压，内存资源会紧张；</li>
</ul>
<p>所以，能不能将 Redis 作为消息队列来使用，关键看你的业务场景：</p>
<ul>
<li>如果你的业务场景足够简单，对于数据丢失不敏感，而且消息积压概率比较小的情况下，把 Redis 当作队列是完全可以的。</li>
<li>如果你的业务有海量消息，消息积压的概率比较大，并且不能接受数据丢失，那么还是用专业的消息队列中间件吧。</li>
</ul>
<p><strong>Redis 发布/订阅机制为什么不可以作为消息队列？</strong></p>
<p>发布订阅机制存在以下缺点，都是跟丢失数据有关：</p>
<ol>
<li>发布/订阅机制没有基于任何数据类型实现，所以不具备「数据持久化」的能力，也就是发布/订阅机制的相关操作，不会写入到 RDB 和 AOF 中，当 Redis 宕机重启，发布/订阅机制的数据也会全部丢失。</li>
<li>发布订阅模式是“发后既忘”的工作模式，如果有订阅者离线重连之后不能消费之前的历史消息。</li>
<li>当消费端有一定的消息积压时，也就是生产者发送的消息，消费者消费不过来时，如果超过 32M 或者是 60s 内持续保持在 8M 以上，消费端会被强行断开，这个参数是在配置文件中设置的，默认值是 <code>client-output-buffer-limit pubsub 32mb 8mb 60</code>。</li>
</ol>
<p>所以，发布/订阅机制只适合即时通讯的场景，比如<strong>构建哨兵集群</strong>的场景采用了发布/订阅机制。</p>
<h2 id="线程模型"><a href="#线程模型" class="headerlink" title="线程模型"></a>线程模型</h2><h3 id="单线程"><a href="#单线程" class="headerlink" title="单线程"></a>单线程</h3><p><strong>Redis 单线程指的是「接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端」这个过程是由一个线程（主线程）来完成的</strong>，这也是我们常说 Redis 是单线程的原因。</p>
<p>但是，<strong>Redis 程序并不是单线程的</strong>，Redis 在启动的时候，是会<strong>启动后台线程</strong>（BIO）的：</p>
<ul>
<li><strong>Redis 在 2.6 版本</strong>，会启动 2 个后台线程，分别处理关闭文件、AOF 刷盘这两个任务；</li>
<li><strong>Redis 在 4.0 版本之后</strong>，新增了一个新的后台线程，用来异步释放 Redis 内存，也就是 lazyfree 线程。例如执行 unlink key / flushdb async / flushall async 等命令，会把这些删除操作交给后台线程来执行，好处是不会导致 Redis 主线程卡顿。因此，当我们要删除一个大 key 的时候，不要使用 del 命令删除，因为 del 是在主线程处理的，这样会导致 Redis 主线程卡顿，因此我们应该使用 unlink 命令来异步删除大key。</li>
</ul>
<p>之所以 Redis 为「关闭文件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求了。</p>
<p>后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。</p>
<p><img src="%E5%8D%95%E7%BA%BF%E7%A8%8B.jpg" alt="单线程"></p>
<p>关闭文件、AOF 刷盘、释放内存这三个任务都有各自的任务队列：</p>
<ul>
<li>BIO_CLOSE_FILE，关闭文件任务队列：当队列有任务后，后台线程会调用 close(fd) ，将文件关闭；</li>
<li>BIO_AOF_FSYNC，AOF刷盘任务队列：当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到队列中。当发现队列有任务后，后台线程会调用 fsync(fd)，将 AOF 文件刷盘，</li>
<li>BIO_LAZY_FREE，lazy free 任务队列：当队列有任务后，后台线程会 free(obj) 释放对象 / free(dict) 删除数据库所有对象 / free(skiplist) 释放跳表对象；</li>
</ul>
<h3 id="单线程模式"><a href="#单线程模式" class="headerlink" title="单线程模式"></a>单线程模式</h3><p>Redis 6.0 版本之前的单线模式如下图：</p>
<p><img src="%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%BC%8F.png" alt="单线程模式"></p>
<p>图中的蓝色部分是一个事件循环，是由主线程负责的，可以看到网络 I/O 和命令处理都是单线程。 Redis 初始化的时候，会做下面这几件事情：</p>
<ul>
<li>首先，调用 epoll_create() 创建一个 epoll 对象和调用 socket() 创建一个服务端 socket</li>
<li>然后，调用 bind() 绑定端口和调用 listen() 监听该 socket；</li>
<li>然后，将调用 epoll_ctl() 将 listen socket 加入到 epoll，同时注册「连接事件」处理函数。</li>
</ul>
<p>初始化完后，主线程就进入到一个<strong>事件循环函数</strong>，主要会做以下事情：</p>
<ul>
<li>首先，先调用<strong>处理发送队列函数</strong>，看是发送队列里是否有任务，如果有发送任务，则通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。</li>
<li>接着，调用 epoll_wait 函数等待事件的到来：<ul>
<li>如果是<strong>连接事件</strong>到来，则会调用<strong>连接事件处理函数</strong>，该函数会做这些事情：调用 accpet 获取已连接的 socket -&gt; 调用 epoll_ctl 将已连接的 socket 加入到 epoll -&gt; 注册「读事件」处理函数；</li>
<li>如果是<strong>读事件</strong>到来，则会调用<strong>读事件处理函数</strong>，该函数会做这些事情：调用 read 获取客户端发送的数据 -&gt; 解析命令 -&gt; 处理命令 -&gt; 将客户端对象添加到发送队列 -&gt; 将执行结果写到发送缓存区等待发送；</li>
<li>如果是<strong>写事件</strong>到来，则会调用<strong>写事件处理函数</strong>，该函数会做这些事情：通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会继续注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。</li>
</ul>
</li>
</ul>
<h3 id="单线程为什么还这么快"><a href="#单线程为什么还这么快" class="headerlink" title="单线程为什么还这么快"></a>单线程为什么还这么快</h3><p>官方使用基准测试的结果是，<strong>单线程的 Redis 吞吐量可以达到 10W/每秒</strong>。</p>
<p>之所以 Redis 采用单线程（网络 I/O 和执行命令）那么快，有如下几个原因：</p>
<ul>
<li>Redis 的大部分操作<strong>都在内存中完成</strong>，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；</li>
<li>Redis 采用单线程模型可以<strong>避免了多线程之间的竞争</strong>，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。</li>
<li>Redis 采用了 <strong>I/O 多路复用机制</strong>处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</li>
</ul>
<h3 id="Redis-6-0-之前为什么使用单线程"><a href="#Redis-6-0-之前为什么使用单线程" class="headerlink" title="Redis 6.0 之前为什么使用单线程"></a>Redis 6.0 之前为什么使用单线程</h3><p>我们都知道单线程的程序是无法利用服务器的多核 CPU 的，那么早期 Redis 版本的主要工作（网络 I/O 和执行命令）为什么还要使用单线程呢？</p>
<p>官方的核心原因是：<strong>CPU 并不是制约 Redis 性能表现的瓶颈所在</strong>，更多情况下是受到内存大小和网络I/O的限制，所以 Redis 核心网络模型使用单线程并没有什么问题，如果你想要使用服务的多核CPU，可以在一台服务器上启动多个节点或者采用分片集群的方式。</p>
<p>除了上面的官方回答，选择单线程的原因也有下面的考虑。</p>
<p>使用了单线程后，可维护性高，多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，<strong>增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗</strong>。</p>
<h3 id="Redis-6-0-之后为什么引入了多线程"><a href="#Redis-6-0-之后为什么引入了多线程" class="headerlink" title="Redis 6.0 之后为什么引入了多线程"></a>Redis 6.0 之后为什么引入了多线程</h3><p>虽然 Redis 的主要工作（网络 I/O 和执行命令）一直是单线程模型，但是<strong>在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求</strong>，<strong>这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上</strong>。</p>
<p>所以为了提高网络 I/O 的并行度，Redis 6.0 对于网络 I/O 采用多线程来处理。<strong>但是对于命令的执行，Redis 仍然使用单线程来处理，</strong>所以大家不要误解 Redis 有多线程同时执行命令。</p>
<p>Redis 官方表示，<strong>Redis 6.0 版本引入的多线程 I/O 特性对性能提升至少是一倍以上</strong>。</p>
<p>Redis 6.0 版本支持的 I/O 多线程特性，默认情况下 I/O 多线程只针对发送响应数据（write client socket），并不会以多线程的方式处理读请求（read client socket）。要想开启多线程处理客户端读请求，就需要把 Redis.conf 配置文件中的 io-threads-do-reads 配置项设为 yes。</p>
<p>关于线程数的设置，官方的建议是如果为 4 核的 CPU，建议线程数设置为 2 或 3，如果为 8 核 CPU 建议线程数设置为 6，线程数一定要小于机器核数，线程数并不是越大越好。</p>
<p>因此， Redis 6.0 版本之后，Redis 在启动的时候，默认情况下会<strong>额外创建 6 个线程</strong>（<em>这里的线程数不包括主线程</em>）：</p>
<ul>
<li>Redis-server ： Redis的主线程，主要负责执行命令；</li>
<li>bio_close_file、bio_aof_fsync、bio_lazy_free：三个后台线程，分别异步处理关闭文件任务、AOF刷盘任务、释放内存任务；</li>
<li>io_thd_1、io_thd_2、io_thd_3：三个 I/O 线程，io-threads 默认是 4 ，所以会启动 3（4-1）个 I/O 多线程，用来分担 Redis 网络 I/O 的压力。</li>
</ul>
<h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><h3 id="Redis-如何实现数据不丢失"><a href="#Redis-如何实现数据不丢失" class="headerlink" title="Redis 如何实现数据不丢失"></a>Redis 如何实现数据不丢失</h3><p>Redis 的读写操作都是在内存中，所以 Redis 性能才会高，但是当 Redis 重启后，内存中的数据就会丢失，那为了保证内存中的数据不会丢失，Redis 实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。</p>
<p>Redis 共有三种数据持久化的方式：</p>
<ul>
<li><strong>AOF 日志</strong>：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；</li>
<li><strong>RDB 快照</strong>：将某一时刻的内存数据，以二进制的方式写入磁盘；</li>
<li><strong>混合持久化方式</strong>：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点；</li>
</ul>
<h3 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h3><p>Redis 在执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件里，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。</p>
<p><img src="AOF.png" alt="AOF"></p>
<p><img src="AOF2.png" alt="AOF"></p>
<p>「*3」表示当前命令有三个部分，每部分都是以「$+数字」开头，后面紧跟着具体的命令、键或值。然后，这里的「数字」表示这部分中的命令、键或值一共有多少字节。例如，「$3 set」表示这部分有 3 个字节，也就是「set」命令这个字符串的长度。</p>
<h4 id="为什么先执行命令，再把数据写入日志"><a href="#为什么先执行命令，再把数据写入日志" class="headerlink" title="为什么先执行命令，再把数据写入日志"></a>为什么先执行命令，再把数据写入日志</h4><p>Redis 是先执行写操作命令后，才将该命令记录到 AOF 日志里的，这么做其实有两个好处。</p>
<ul>
<li><strong>避免额外的检查开销</strong>：因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。</li>
<li><strong>不会阻塞当前写操作命令的执行</strong>：因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。</li>
</ul>
<p>当然，这样做也会带来风险：</p>
<ul>
<li><strong>数据可能会丢失：</strong> 执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有丢失的风险。</li>
<li><strong>可能阻塞其他操作：</strong> 由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前命令的执行，但因为 AOF 日志也是在主线程中执行，所以当 Redis 把日志文件写入磁盘的时候，还是会阻塞后续的操作无法执行。</li>
</ul>
<h4 id="AOF-写回策略有几种"><a href="#AOF-写回策略有几种" class="headerlink" title="AOF 写回策略有几种"></a>AOF 写回策略有几种</h4><p>先来看看，Redis 写入 AOF 日志的过程，如下图：</p>
<p><img src="AOF3.png" alt="AOF"></p>
<p>具体说说：</p>
<ol>
<li>Redis 执行完写操作命令后，会将命令追加到 server.aof_buf 缓冲区；</li>
<li>然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘；</li>
<li>具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。</li>
</ol>
<p>Redis 提供了 3 种写回硬盘的策略，控制的就是上面说的第三步的过程。 在 Redis.conf 配置文件中的 appendfsync 配置项可以有以下 3 种参数可填：</p>
<ul>
<li><strong>Always</strong>，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；</li>
<li><strong>Everysec</strong>，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；</li>
<li><strong>No</strong>，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。</li>
</ul>
<p><img src="AOF4.png" alt="AOF"></p>
<h4 id="AOF-日志过大，会触发什么机制"><a href="#AOF-日志过大，会触发什么机制" class="headerlink" title="AOF 日志过大，会触发什么机制"></a>AOF 日志过大，会触发什么机制</h4><p>AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。 如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。</p>
<p>所以，Redis 为了避免 AOF 文件越写越大，提供了 <strong>AOF 重写机制</strong>，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。</p>
<p>AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。</p>
<p>举个例子，在没有使用重写机制前，假设前后执行了「<em>set name xiaolin</em>」和「<em>set name xiaolincoding</em>」这两个命令的话，就会将这两个命令记录到 AOF 文件。</p>
<p><img src="AOF5.png" alt="AOF"></p>
<p>但是<strong>在使用重写机制后，就会读取 name 最新的 value（键值对） ，然后用一条 「set name xiaolincoding」命令记录到新的 AOF 文件</strong>，之前的第一个命令就没有必要记录了，因为它属于「历史」命令，没有作用了。这样一来，一个键值对在重写日志中只用一条命令就行了。</p>
<p>重写工作完成后，就会将新的 AOF 文件覆盖现有的 AOF 文件，这就相当于压缩了 AOF 文件，使得 AOF 文件体积变小了。</p>
<h3 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h3><p>Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：</p>
<ul>
<li>执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，<strong>会阻塞主线程</strong>；</li>
<li>执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以<strong>避免主线程的阻塞</strong>；</li>
</ul>
<p>Redis 还可以通过配置文件的选项来实现每隔一段时间自动执行一次 bgsave 命令，默认会提供以下配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure>

<p>别看选项名叫 save，实际上执行的是 bgsave 命令，也就是会创建子进程来生成 RDB 快照文件。 只要满足上面条件的任意一个，就会执行 bgsave，它们的意思分别是：</p>
<ul>
<li>900 秒之内，对数据库进行了至少 1 次修改；</li>
<li>300 秒之内，对数据库进行了至少 10 次修改；</li>
<li>60 秒之内，对数据库进行了至少 10000 次修改。</li>
</ul>
<p>这里提一点，Redis 的快照是<strong>全量快照</strong>，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。所以执行快照是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多。</p>
<h4 id="RDB-在执行快照的时候，数据能修改吗"><a href="#RDB-在执行快照的时候，数据能修改吗" class="headerlink" title="RDB 在执行快照的时候，数据能修改吗"></a>RDB 在执行快照的时候，数据能修改吗</h4><p>可以的，执行 bgsave 过程中，Redis 依然<strong>可以继续处理操作命令</strong>的，也就是数据是能被修改的，关键的技术就在于<strong>写时复制技术（Copy-On-Write, COW）。</strong></p>
<p>执行 bgsave 命令的时候，会通过 fork() 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个，此时如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响。</p>
<p><img src="RDB.png" alt="RDB"></p>
<p>如果主线程执行写操作，则被修改的数据会复制一份副本，然后 bgsave 子进程会把该副本数据写入 RDB 文件，在这个过程中，主线程仍然可以直接修改原来的数据。</p>
<p><img src="RDB2.png" alt="RDB"></p>
<h3 id="为什么会有混合持久化"><a href="#为什么会有混合持久化" class="headerlink" title="为什么会有混合持久化"></a>为什么会有混合持久化</h3><p>RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。</p>
<p>AOF 优点是丢失数据少，但是数据恢复不快。</p>
<p>为了集成了两者的优点， Redis 4.0 提出了<strong>混合使用 AOF 日志和内存快照</strong>，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。</p>
<p>混合持久化工作在 <strong>AOF 日志重写过程</strong>，当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。</p>
<p>也就是说，使用了混合持久化，AOF 文件的<strong>前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据</strong>。</p>
<p><img src="%E6%B7%B7%E5%90%88%E6%8C%81%E4%B9%85%E5%8C%96.png" alt="混合持久化"></p>
<p>这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样<strong>加载的时候速度会很快</strong>。</p>
<p>加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得<strong>数据更少的丢失</strong>。</p>
<p><strong>混合持久化优点：</strong></p>
<ul>
<li>混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。</li>
</ul>
<p><strong>混合持久化缺点：</strong></p>
<ul>
<li>AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；</li>
<li>兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。</li>
</ul>
<h3 id="大-Key-对持久化的影响"><a href="#大-Key-对持久化的影响" class="headerlink" title="大 Key 对持久化的影响"></a>大 Key 对持久化的影响</h3><p>当 AOF 写回策略配置了 Always 策略，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的。</p>
<p>AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 <code>fork()</code> 函数创建一个子进程来处理任务。会有两个阶段会导致阻塞父进程（主线程）：</p>
<ul>
<li>创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；</li>
<li>创建完子进程后，如果父进程修改了共享数据中的大 Key，就会发生写时复制，这期间会拷贝物理内存，由于大 Key 占用的物理内存会很大，那么在复制物理内存这一过程，就会比较耗时，所以有可能会阻塞父进程。</li>
</ul>
<p>大 key 除了会影响持久化之外，还会有以下的影响。</p>
<ul>
<li>客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li>
<li>引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li>
<li>阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</li>
<li>内存分布不均。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</li>
</ul>
<p>如何避免大 Key 呢？</p>
<p>最好在设计阶段，就把大 key 拆分成一个一个小 key。或者，定时检查 Redis 是否存在大 key ，如果该大 key 是可以删除的，不要使用 DEL 命令删除，因为该命令删除过程会阻塞主线程，而是用 unlink 命令（Redis 4.0+）删除大 key，因为该命令的删除过程是异步的，不会阻塞主线程。</p>
<h2 id="Redis集群"><a href="#Redis集群" class="headerlink" title="Redis集群"></a>Redis集群</h2><h3 id="如何实现服务高可用"><a href="#如何实现服务高可用" class="headerlink" title="如何实现服务高可用"></a>如何实现服务高可用</h3><p>要想设计一个高可用的 Redis 服务，一定要从 Redis 的多服务节点来考虑，比如 Redis 的主从复制、哨兵模式、切片集群。</p>
<h4 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h4><p>主从复制是 Redis 高可用服务的最基础的保证，实现方案就是将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，且主从服务器之间采用的是「读写分离」的方式。</p>
<p>主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。</p>
<p><img src="%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.png" alt="主从复制"></p>
<p>也就是说，所有的数据修改只在主服务器上进行，然后将最新的数据同步给从服务器，这样就使得主从服务器的数据是一致的。</p>
<p>注意，主从服务器之间的命令复制是<strong>异步</strong>进行的。</p>
<p>具体来说，在主从服务器命令传播阶段，主服务器收到新的写命令后，会发送给从服务器。但是，主服务器并不会等到从服务器实际执行完命令后，再把结果返回给客户端，而是主服务器自己在本地执行完命令后，就会向客户端返回结果了。如果从服务器还没有执行主服务器同步过来的命令，主从服务器间的数据就不一致了。</p>
<p>所以，无法实现强一致性保证（主从数据时时刻刻保持一致），数据不一致是难以避免的。</p>
<h4 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h4><p>在使用 Redis 主从服务的时候，会有一个问题，就是当 Redis 的主从服务器出现故障宕机时，需要手动进行恢复。</p>
<p>为了解决这个问题，Redis 增加了哨兵模式（<strong>Redis Sentinel</strong>），因为哨兵模式做到了可以监控主从服务器，并且提供<strong>主从节点故障转移的功能。</strong></p>
<p><img src="%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F.png" alt="哨兵模式"></p>
<h4 id="切片集群模式"><a href="#切片集群模式" class="headerlink" title="切片集群模式"></a>切片集群模式</h4><p>当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 <strong>Redis 切片集群</strong>（Redis Cluster ）方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。</p>
<p>Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。在 Redis Cluster 方案中，<strong>一个切片集群共有 16384 个哈希槽</strong>，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程分为两大步：</p>
<ul>
<li>根据键值对的 key，按照 <a href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check" target="_blank" rel="noopener">CRC16 算法 (opens new window)</a>计算一个 16 bit 的值。</li>
<li>再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。</li>
</ul>
<p>接下来的问题就是，这些哈希槽怎么被映射到具体的 Redis 节点上的呢？有两种方案：</p>
<ul>
<li><strong>平均分配：</strong> 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384/9 个。</li>
<li><strong>手动分配：</strong> 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。</li>
</ul>
<p>为了方便你的理解，我通过一张图来解释数据、哈希槽，以及节点三者的映射分布关系。</p>
<p><img src="%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4.jpg" alt="切片集群"></p>
<p>上图中的切片集群一共有 2 个节点，假设有 4 个哈希槽（Slot 0～Slot 3）时，我们就可以通过命令手动分配哈希槽，比如节点 1 保存哈希槽 0 和 1，节点 2 保存哈希槽 2 和 3。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 192.168.1.10 –p 6379 cluster addslots 0,1</span><br><span class="line">redis-cli -h 192.168.1.11 –p 6379 cluster addslots 2,3</span><br></pre></td></tr></table></figure>

<p>然后在集群运行的过程中，key1 和 key2 计算完 CRC16 值后，对哈希槽总个数 4 进行取模，再根据各自的模数结果，就可以被映射到哈希槽 1（对应节点1） 和 哈希槽 2（对应节点2）。</p>
<p>需要注意的是，在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。</p>
<h3 id="集群脑裂导致数据丢失怎么办"><a href="#集群脑裂导致数据丢失怎么办" class="headerlink" title="集群脑裂导致数据丢失怎么办"></a>集群脑裂导致数据丢失怎么办</h3><h4 id="什么是脑裂"><a href="#什么是脑裂" class="headerlink" title="什么是脑裂"></a>什么是脑裂</h4><p>先来理解集群的脑裂现象，这就好比一个人有两个大脑，那么到底受谁控制呢？</p>
<p>那么在 Redis 中，集群脑裂产生数据丢失的现象是怎样的呢？</p>
<p>在 Redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。 如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 Redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据（过程A），此时这些数据被旧主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。</p>
<p>这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在「从节点」中选举出一个 leader 作为主节点，这时集群就有两个主节点了 —— <strong>脑裂出现了</strong>。</p>
<p>然后，网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，<strong>因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题</strong>。</p>
<p>总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。</p>
<h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。</p>
<p>在 Redis 的配置文件中有两个参数我们可以设置：</p>
<ul>
<li>min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。</li>
<li>min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。</li>
</ul>
<p>我们可以把 min-slaves-to-write 和 min-slaves-max-lag 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T。</p>
<p>这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的写请求了。</p>
<p>即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，<strong>原主库就会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了</strong>。</p>
<p><strong>等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。</strong></p>
<p>再来举个例子。</p>
<p>假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 12s，把哨兵的 down-after-milliseconds 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。</p>
<p>同时，因为原主库卡住了 15s，没有一个从库能和原主库在 12s 内进行数据复制，原主库也无法接收客户端请求了。</p>
<p>这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。</p>
<h2 id="淘汰策略"><a href="#淘汰策略" class="headerlink" title="淘汰策略"></a>淘汰策略</h2><h3 id="Redis-使用的过期删除策略是什么"><a href="#Redis-使用的过期删除策略是什么" class="headerlink" title="Redis 使用的过期删除策略是什么"></a>Redis 使用的过期删除策略是什么</h3><p>Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。</p>
<p>每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个<strong>过期字典</strong>（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。</p>
<p>当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：</p>
<ul>
<li>如果不在，则正常读取键值；</li>
<li>如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。</li>
</ul>
<p>Redis 使用的过期删除策略是「<strong>惰性删除+定期删除</strong>」这两种策略配和使用。</p>
<h4 id="惰性删除策略"><a href="#惰性删除策略" class="headerlink" title="惰性删除策略"></a>惰性删除策略</h4><p>惰性删除策略的做法是，<strong>不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。</strong></p>
<p>惰性删除的流程图如下：</p>
<p><img src="%E6%83%B0%E6%80%A7%E5%88%A0%E9%99%A4.jpg" alt="惰性删除"></p>
<p>惰性删除策略的<strong>优点</strong>：</p>
<ul>
<li>因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 CPU 时间最友好。</li>
</ul>
<p>惰性删除策略的<strong>缺点</strong>：</p>
<ul>
<li>如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以，惰性删除策略对内存不友好。</li>
</ul>
<h4 id="定期删除策略"><a href="#定期删除策略" class="headerlink" title="定期删除策略"></a>定期删除策略</h4><p>定期删除策略的做法是，<strong>每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。</strong></p>
<p>Redis 的定期删除的流程：</p>
<ol>
<li>从过期字典中随机抽取 20 个 key；</li>
<li>检查这 20 个 key 是否过期，并删除已过期的 key；</li>
<li>如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。</li>
</ol>
<p>可以看到，定期删除是一个循环的流程。那 Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms。</p>
<p>定期删除的流程如下：</p>
<p><img src="%E5%AE%9A%E6%9C%9F%E5%88%A0%E9%99%A4.jpg" alt="定期删除"></p>
<p>定期删除策略的<strong>优点</strong>：</p>
<ul>
<li>通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。</li>
</ul>
<p>定期删除策略的<strong>缺点</strong>：</p>
<ul>
<li>难以确定删除操作执行的时长和频率。如果执行的太频繁，就会对 CPU 不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。</li>
</ul>
<p>可以看到，惰性删除策略和定期删除策略都有各自的优点，所以 <strong>Redis 选择「惰性删除+定期删除」这两种策略配和使用</strong>，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。</p>
<h3 id="Redis-持久化时，对过期键会如何处理"><a href="#Redis-持久化时，对过期键会如何处理" class="headerlink" title="Redis 持久化时，对过期键会如何处理"></a>Redis 持久化时，对过期键会如何处理</h3><p>Redis 持久化文件有两种格式：RDB（Redis Database）和 AOF（Append Only File），下面我们分别来看过期键在这两种格式中的呈现状态。</p>
<p>RDB 文件分为两个阶段，RDB 文件生成阶段和加载阶段。</p>
<ul>
<li><p><strong>RDB 文件生成阶段</strong>：从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，<strong>过期的键「不会」被保存到新的 RDB 文件中</strong>，因此 Redis 中的过期键不会对生成新 RDB 文件产生任何影响。</p>
</li>
<li><p>RDB 加载阶段</p>
<p>：RDB 加载阶段时，要看服务器是主服务器还是从服务器，分别对应以下两种情况：</p>
<ul>
<li><strong>如果 Redis 是「主服务器」运行模式的话，在载入 RDB 文件时，程序会对文件中保存的键进行检查，过期键「不会」被载入到数据库中</strong>。所以过期键不会对载入 RDB 文件的主服务器造成影响；</li>
<li><strong>如果 Redis 是「从服务器」运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中</strong>。但由于主从服务器在进行数据同步时，从服务器的数据会被清空。所以一般来说，过期键对载入 RDB 文件的从服务器也不会造成影响。</li>
</ul>
</li>
</ul>
<p>AOF 文件分为两个阶段，AOF 文件写入阶段和 AOF 重写阶段。</p>
<ul>
<li><strong>AOF 文件写入阶段</strong>：当 Redis 以 AOF 模式持久化时，<strong>如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值</strong>。</li>
<li><strong>AOF 重写阶段</strong>：执行 AOF 重写时，会对 Redis 中的键值对进行检查，<strong>已过期的键不会被保存到重写后的 AOF 文件中</strong>，因此不会对 AOF 重写造成任何影响。</li>
</ul>
<h3 id="Redis-主从模式中，对过期键会如何处理"><a href="#Redis-主从模式中，对过期键会如何处理" class="headerlink" title="Redis 主从模式中，对过期键会如何处理"></a>Redis 主从模式中，对过期键会如何处理</h3><p>当 Redis 运行在主从模式下时，<strong>从库不会进行过期扫描，从库对过期的处理是被动的</strong>。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。</p>
<p>从库的过期键处理依靠主服务器控制，<strong>主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库</strong>，从库通过执行这条 del 指令来删除过期的 key。</p>
<h3 id="Redis-内存满了，会发生什么"><a href="#Redis-内存满了，会发生什么" class="headerlink" title="Redis 内存满了，会发生什么"></a>Redis 内存满了，会发生什么</h3><p>在 Redis 的运行内存达到了某个阀值，就会触发<strong>内存淘汰机制</strong>，这个阀值就是我们设置的最大运行内存，此值在 Redis 的配置文件中可以找到，配置项为 maxmemory。</p>
<h3 id="Redis-内存淘汰策略"><a href="#Redis-内存淘汰策略" class="headerlink" title="Redis 内存淘汰策略"></a>Redis 内存淘汰策略</h3><p>Redis 内存淘汰策略共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。</p>
<p><strong><em>1、不进行数据淘汰的策略</em></strong></p>
<p><strong>noeviction</strong>（Redis3.0之后，默认的内存淘汰策略） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，而是不再提供服务，直接返回错误。</p>
<p><strong><em>2、进行数据淘汰的策略</em></strong></p>
<p>针对「进行数据淘汰」这一类策略，又可以细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。 在设置了过期时间的数据中进行淘汰：</p>
<ul>
<li><strong>volatile-random</strong>：随机淘汰设置了过期时间的任意键值；</li>
<li><strong>volatile-ttl</strong>：优先淘汰更早过期的键值。</li>
<li><strong>volatile-lru</strong>（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；</li>
<li><strong>volatile-lfu</strong>（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；</li>
</ul>
<p>在所有数据范围内进行淘汰：</p>
<ul>
<li><strong>allkeys-random</strong>：随机淘汰任意键值;</li>
<li><strong>allkeys-lru</strong>：淘汰整个键值中最久未使用的键值；</li>
<li><strong>allkeys-lfu</strong>（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。</li>
</ul>
<h4 id="LRU"><a href="#LRU" class="headerlink" title="LRU"></a>LRU</h4><p><strong>LRU</strong> 全称是 Least Recently Used 翻译为<strong>最近最少使用</strong>，会选择淘汰最近最少使用的数据。</p>
<p>传统 LRU 算法的实现是基于「链表」结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，只需要删除链表尾部的元素即可，因为链表尾部的元素就代表最久未被使用的元素。</p>
<p>Redis 并没有使用这样的方式实现 LRU 算法，因为传统的 LRU 算法存在两个问题：</p>
<ul>
<li>需要用链表管理所有的缓存数据，这会带来额外的空间开销；</li>
<li>当有数据被访问时，需要在链表上把该数据移动到头端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。</li>
</ul>
<p>Redis 实现的是一种<strong>近似 LRU 算法</strong>，目的是为了更好的节约内存，它的<strong>实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间</strong>。</p>
<p>当 Redis 进行内存淘汰时，会使用<strong>随机采样的方式来淘汰数据</strong>，它是随机取 5 个值（此值可配置），然后<strong>淘汰最久没有使用的那个</strong>。</p>
<p>Redis 实现的 LRU 算法的优点：</p>
<ul>
<li>不用为所有的数据维护一个大链表，节省了空间占用；</li>
<li>不用在每次数据访问时都移动链表项，提升了缓存的性能；</li>
</ul>
<p>但是 LRU 算法有一个问题，<strong>无法解决缓存污染问题</strong>，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。</p>
<p>因此，在 Redis 4.0 之后引入了 LFU 算法来解决这个问题。</p>
<h4 id="LFU"><a href="#LFU" class="headerlink" title="LFU"></a>LFU</h4><p>LFU 全称是 Least Frequently Used 翻译为<strong>最近最不常用的</strong>，LFU 算法是根据数据访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。</p>
<p>所以， LFU 算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。这样就解决了偶尔被访问一次之后，数据留存在缓存中很长一段时间的问题，相比于 LRU 算法也更合理一些。</p>
<p>LFU 算法相比于 LRU 算法的实现，多记录了「数据的访问频次」的信息。</p>
<h2 id="缓存设计"><a href="#缓存设计" class="headerlink" title="缓存设计"></a>缓存设计</h2><h3 id="缓存雪崩、缓存击穿、缓存穿透"><a href="#缓存雪崩、缓存击穿、缓存穿透" class="headerlink" title="缓存雪崩、缓存击穿、缓存穿透"></a>缓存雪崩、缓存击穿、缓存穿透</h3><h4 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h4><p>通常我们为了保证缓存中的数据与数据库中的数据一致性，会给 Redis 里的数据设置过期时间，当缓存数据过期后，用户访问的数据如果不在缓存里，业务系统需要重新生成缓存，因此就会访问数据库，并将数据更新到 Redis 里，这样后续请求都可以直接命中缓存。</p>
<p><img src="%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9.png" alt="缓存雪崩"></p>
<p>那么，当<strong>大量缓存数据在同一时间过期（失效）\</strong>时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是*<em>缓存雪崩*</em>的问题。</p>
<p>对于缓存雪崩问题，我们可以采用两种方案解决。</p>
<ul>
<li><strong>将缓存失效时间随机打散：</strong> 我们可以在原有的失效时间基础上增加一个随机值（比如 1 到 10 分钟）这样每个缓存的过期时间都不重复了，也就降低了缓存集体失效的概率。</li>
<li><strong>设置缓存不过期：</strong> 我们可以通过后台服务来更新缓存数据，从而避免因为缓存失效造成的缓存雪崩，也可以在一定程度上避免缓存并发问题。</li>
</ul>
<h4 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h4><p>我们的业务通常会有几个数据会被频繁地访问，比如秒杀活动，这类被频地访问的数据被称为热点数据。</p>
<p>如果缓存中的<strong>某个热点数据过期</strong>了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是<strong>缓存击穿</strong>的问题。</p>
<p><img src="%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF.png" alt="缓存击穿"></p>
<p>可以发现缓存击穿跟缓存雪崩很相似，你可以认为缓存击穿是缓存雪崩的一个子集。 应对缓存击穿可以采取前面说到两种方案：</p>
<ul>
<li>互斥锁方案（Redis 中使用 setNX 方法设置一个状态位，表示这是一种锁定状态），保证同一时间只有一个业务线程请求缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。</li>
<li>不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；</li>
</ul>
<h4 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h4><p>当发生缓存雪崩或击穿时，数据库中还是保存了应用要访问的数据，一旦缓存恢复相对应的数据，就可以减轻数据库的压力，而缓存穿透就不一样了。</p>
<p>当用户访问的数据，<strong>既不在缓存中，也不在数据库中</strong>，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是<strong>缓存穿透</strong>的问题。</p>
<p><img src="%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F.png" alt="缓存穿透"></p>
<p>缓存穿透的发生一般有这两种情况：</p>
<ul>
<li>业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；</li>
<li>黑客恶意攻击，故意大量访问某些读取不存在数据的业务；</li>
</ul>
<p>应对缓存穿透的方案，常见的方案有三种。</p>
<ul>
<li><strong>非法请求的限制</strong>：当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。</li>
<li><strong>设置空值或者默认值</strong>：当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。</li>
<li><strong>使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在</strong>：我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在，即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。</li>
</ul>
<h3 id="如何设计一个缓存策略，可以动态缓存热点数据"><a href="#如何设计一个缓存策略，可以动态缓存热点数据" class="headerlink" title="如何设计一个缓存策略，可以动态缓存热点数据"></a>如何设计一个缓存策略，可以动态缓存热点数据</h3><p>由于数据存储受限，系统并不是将所有数据都需要存放到缓存中的，而<strong>只是将其中一部分热点数据缓存起来</strong>，所以我们要设计一个热点数据动态缓存的策略。</p>
<p>热点数据动态缓存的策略总体思路：<strong>通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据</strong>。</p>
<p>以电商平台场景中的例子，现在要求只缓存用户经常访问的 Top 1000 的商品。具体细节如下：</p>
<ul>
<li>先通过缓存系统做一个排序队列（比如存放 1000 个商品），系统会根据商品的访问时间，更新队列信息，越是最近访问的商品排名越靠前；</li>
<li>同时系统会定期过滤掉队列中排名最后的 200 个商品，然后再从数据库中随机读取出 200 个商品加入队列中；</li>
<li>这样当请求每次到达的时候，会先从队列中获取商品 ID，如果命中，就根据 ID 再从另一个缓存数据结构中读取实际的商品信息，并返回。</li>
</ul>
<p>在 Redis 中可以用 zadd 方法和 zrange 方法来完成排序队列和获取 200 个商品的操作。</p>
<h3 id="常见的缓存更新策略"><a href="#常见的缓存更新策略" class="headerlink" title="常见的缓存更新策略"></a>常见的缓存更新策略</h3><p>常见的缓存更新策略共有3种：</p>
<ul>
<li>Cache Aside（旁路缓存）策略；</li>
<li>Read/Write Through（读穿 / 写穿）策略；</li>
<li>Write Back（写回）策略；</li>
</ul>
<p>实际开发中，Redis 和 MySQL 的更新策略用的是 Cache Aside，另外两种策略应用不了。</p>
<h4 id="Cache-Aside"><a href="#Cache-Aside" class="headerlink" title="Cache Aside"></a>Cache Aside</h4><p>Cache Aside（旁路缓存）策略是最常用的，应用程序直接与「数据库、缓存」交互，并负责对缓存的维护，该策略又可以细分为「读策略」和「写策略」。</p>
<p><img src="cache-aside.png" alt="cache-aside"></p>
<p><strong>写策略的步骤：</strong></p>
<ul>
<li>先更新数据库中的数据，再删除缓存中的数据。</li>
</ul>
<p><strong>读策略的步骤：</strong></p>
<ul>
<li>如果读取的数据命中了缓存，则直接返回数据；</li>
<li>如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。</li>
</ul>
<p>注意，写策略的步骤的顺序不能倒过来，即<strong>不能先删除缓存再更新数据库</strong>，原因是在「读+写」并发的时候，会出现缓存和数据库的数据不一致性的问题。</p>
<p>举个例子，假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21。</p>
<p><img src="cache-aside2.png" alt="cache-aside"></p>
<p>最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库的数据不一致。</p>
<p><strong>为什么「先更新数据库再删除缓存」不会有数据不一致的问题？</strong></p>
<p>继续用「读 + 写」请求的并发的场景来分析。</p>
<p>假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中。</p>
<p><img src="cache-aside3.png" alt="cache-aside"></p>
<p>最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库数据不一致。 从上面的理论上分析，先更新数据库，再删除缓存也是会出现数据不一致性的问题，<strong>但是在实际中，这个问题出现的概率并不高</strong>。</p>
<p><strong>因为缓存的写入通常要远远快于数据库的写入</strong>，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。而一旦请求 A 早于请求 B 删除缓存之前更新了缓存，那么接下来的请求就会因为缓存不命中而从数据库中重新读取数据，所以不会出现这种不一致的情况。</p>
<p><strong>Cache Aside 策略适合读多写少的场景，不适合写多的场景</strong>，因为当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。如果业务对缓存命中率有严格的要求，那么可以考虑两种解决方案：</p>
<ul>
<li>一种做法是在更新数据时也更新缓存，只是在更新缓存前先加一个分布式锁，因为这样在同一时间只允许一个线程更新缓存，就不会产生并发问题了。当然这么做对于写入的性能会有一些影响；</li>
<li>另一种做法同样也是在更新数据时更新缓存，只是给缓存加一个较短的过期时间，这样即使出现缓存不一致的情况，缓存的数据也会很快过期，对业务的影响也是可以接受。</li>
</ul>
<h4 id="Read-Write-Through"><a href="#Read-Write-Through" class="headerlink" title="Read/Write Through"></a>Read/Write Through</h4><p>Read/Write Through（读穿 / 写穿）策略原则是应用程序只和缓存交互，不再和数据库交互，而是由缓存和数据库交互，相当于更新数据库的操作由缓存自己代理了。</p>
<p><strong><em>1. Read Through 策略</em></strong></p>
<p>先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库查询数据，并将结果写入到缓存组件，最后缓存组件将数据返回给应用。</p>
<p><strong><em>2、Write Through 策略</em></strong></p>
<p>当有数据更新的时候，先查询要写入的数据在缓存中是否已经存在：</p>
<ul>
<li>如果缓存中数据已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应用程序更新完成。</li>
<li>如果缓存中数据不存在，直接更新数据库，然后返回；</li>
</ul>
<p>下面是 Read Through/Write Through 策略的示意图：</p>
<p><img src="read-write-through.jpg" alt="read-write-through"></p>
<p>Read Through/Write Through 策略的特点是由缓存节点而非应用程序来和数据库打交道，在我们开发过程中相比 Cache Aside 策略要少见一些，原因是我们经常使用的分布式缓存组件，无论是 Memcached 还是 Redis 都不提供写入数据库和自动加载数据库中的数据的功能。而我们在使用本地缓存的时候可以考虑使用这种策略。</p>
<h4 id="Write-Back"><a href="#Write-Back" class="headerlink" title="Write Back"></a>Write Back</h4><p>Write Back（写回）策略在更新数据的时候，只更新缓存，同时将缓存数据设置为脏的，然后立马返回，并不会更新数据库。对于数据库的更新，会通过批量异步更新的方式进行。</p>
<p>实际上，Write Back（写回）策略也不能应用到我们常用的数据库和缓存的场景中，因为 Redis 并没有异步更新数据库的功能。</p>
<p>Write Back 是计算机体系结构中的设计，比如 CPU 的缓存、操作系统中文件系统的缓存都采用了 Write Back（写回）策略。</p>
<p><strong>Write Back 策略特别适合写多的场景</strong>，因为发生写操作的时候， 只需要更新缓存，就立马返回了。比如，写文件的时候，实际上是写入到文件系统的缓存就返回了，并不会写磁盘。</p>
<p><strong>但是带来的问题是，数据不是强一致性的，而且会有数据丢失的风险</strong>，因为缓存一般使用内存，而内存是非持久化的，所以一旦缓存机器掉电，就会造成原本缓存中的脏数据丢失。所以你会发现系统在掉电之后，之前写入的文件会有部分丢失，就是因为 Page Cache 还没有来得及刷盘造成的。</p>
<h2 id="分布式锁-1"><a href="#分布式锁-1" class="headerlink" title="分布式锁"></a>分布式锁</h2><p>分布式锁是用于分布式环境下并发控制的一种机制，用于控制某个资源在同一时刻只能被一个应用所使用。如下图所示：</p>
<p><img src="%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.jpg" alt="分布式锁"></p>
<p>Redis 本身可以被多个客户端共享访问，正好就是一个共享存储系统，可以用来保存分布式锁，而且 Redis 的读写性能高，可以应对高并发的锁操作场景。</p>
<p>Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：</p>
<ul>
<li>如果 key 不存在，则显示插入成功，可以用来表示加锁成功；</li>
<li>如果 key 存在，则会显示插入失败，可以用来表示加锁失败。</li>
</ul>
<p>基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。</p>
<ul>
<li>加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；</li>
<li>锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间；</li>
<li>锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端；</li>
</ul>
<h2 id="Redis为什么不支持事务回滚"><a href="#Redis为什么不支持事务回滚" class="headerlink" title="Redis为什么不支持事务回滚"></a>Redis为什么不支持事务回滚</h2><p>在事务运行期间虽然Redis命令可能会执行失败，但是Redis依然会执行事务内剩余的命令而不会执行回滚操作。如果你熟悉mysql关系型数据库事务，你会对此非常疑惑，Redis官方的理由如下： 只有当被调用的Redis命令有语法错误时，这条命令才会执行失败（在将这个命令放入事务队列期间，Redis能够发现此类问题），或者对某个键执行不符合其数据类型的操作：实际上，这就意味着只有程序错误才会导致Redis命令执行失败，这种错误很有可能在程序开发期间发现，一般很少在生产环境发现。 支持事务回滚能力会导致设计复杂，这与Redis的初衷相违背，Redis的设计目标是功能简化及确保更快的运行速度。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/redis/" rel="tag"># redis</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/04/22/Go/" rel="prev" title="Golang">
      <i class="fa fa-chevron-left"></i> Golang
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Redis"><span class="nav-number">1.</span> <span class="nav-text">Redis</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#简介"><span class="nav-number">1.1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis-和-Memcached-的区别"><span class="nav-number">1.2.</span> <span class="nav-text">Redis 和 Memcached 的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据结构、使用场景"><span class="nav-number">1.3.</span> <span class="nav-text">数据结构、使用场景</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#热点数据的缓存"><span class="nav-number">1.3.1.</span> <span class="nav-text">热点数据的缓存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#限时业务的运用"><span class="nav-number">1.3.2.</span> <span class="nav-text">限时业务的运用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#计数器相关问题"><span class="nav-number">1.3.3.</span> <span class="nav-text">计数器相关问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分布式锁"><span class="nav-number">1.3.4.</span> <span class="nav-text">分布式锁</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#延时操作"><span class="nav-number">1.3.5.</span> <span class="nav-text">延时操作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#排行榜相关问题"><span class="nav-number">1.3.6.</span> <span class="nav-text">排行榜相关问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#点赞、好友等相互关系的存储"><span class="nav-number">1.3.7.</span> <span class="nav-text">点赞、好友等相互关系的存储</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简单队列"><span class="nav-number">1.3.8.</span> <span class="nav-text">简单队列</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#结构实现"><span class="nav-number">1.3.9.</span> <span class="nav-text">结构实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#String"><span class="nav-number">1.3.9.1.</span> <span class="nav-text">String</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#List"><span class="nav-number">1.3.9.2.</span> <span class="nav-text">List</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hash"><span class="nav-number">1.3.9.3.</span> <span class="nav-text">Hash</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Set"><span class="nav-number">1.3.9.4.</span> <span class="nav-text">Set</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ZSet"><span class="nav-number">1.3.9.5.</span> <span class="nav-text">ZSet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HyperLogLog"><span class="nav-number">1.3.9.6.</span> <span class="nav-text">HyperLogLog</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#布隆过滤器"><span class="nav-number">1.3.9.7.</span> <span class="nav-text">布隆过滤器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#bitmap"><span class="nav-number">1.3.9.8.</span> <span class="nav-text">bitmap</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Stream"><span class="nav-number">1.3.9.9.</span> <span class="nav-text">Stream</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#线程模型"><span class="nav-number">1.4.</span> <span class="nav-text">线程模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#单线程"><span class="nav-number">1.4.1.</span> <span class="nav-text">单线程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#单线程模式"><span class="nav-number">1.4.2.</span> <span class="nav-text">单线程模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#单线程为什么还这么快"><span class="nav-number">1.4.3.</span> <span class="nav-text">单线程为什么还这么快</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-6-0-之前为什么使用单线程"><span class="nav-number">1.4.4.</span> <span class="nav-text">Redis 6.0 之前为什么使用单线程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-6-0-之后为什么引入了多线程"><span class="nav-number">1.4.5.</span> <span class="nav-text">Redis 6.0 之后为什么引入了多线程</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#持久化"><span class="nav-number">1.5.</span> <span class="nav-text">持久化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-如何实现数据不丢失"><span class="nav-number">1.5.1.</span> <span class="nav-text">Redis 如何实现数据不丢失</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AOF"><span class="nav-number">1.5.2.</span> <span class="nav-text">AOF</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#为什么先执行命令，再把数据写入日志"><span class="nav-number">1.5.2.1.</span> <span class="nav-text">为什么先执行命令，再把数据写入日志</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AOF-写回策略有几种"><span class="nav-number">1.5.2.2.</span> <span class="nav-text">AOF 写回策略有几种</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AOF-日志过大，会触发什么机制"><span class="nav-number">1.5.2.3.</span> <span class="nav-text">AOF 日志过大，会触发什么机制</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RDB"><span class="nav-number">1.5.3.</span> <span class="nav-text">RDB</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#RDB-在执行快照的时候，数据能修改吗"><span class="nav-number">1.5.3.1.</span> <span class="nav-text">RDB 在执行快照的时候，数据能修改吗</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么会有混合持久化"><span class="nav-number">1.5.4.</span> <span class="nav-text">为什么会有混合持久化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#大-Key-对持久化的影响"><span class="nav-number">1.5.5.</span> <span class="nav-text">大 Key 对持久化的影响</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis集群"><span class="nav-number">1.6.</span> <span class="nav-text">Redis集群</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#如何实现服务高可用"><span class="nav-number">1.6.1.</span> <span class="nav-text">如何实现服务高可用</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#主从复制"><span class="nav-number">1.6.1.1.</span> <span class="nav-text">主从复制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#哨兵模式"><span class="nav-number">1.6.1.2.</span> <span class="nav-text">哨兵模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#切片集群模式"><span class="nav-number">1.6.1.3.</span> <span class="nav-text">切片集群模式</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#集群脑裂导致数据丢失怎么办"><span class="nav-number">1.6.2.</span> <span class="nav-text">集群脑裂导致数据丢失怎么办</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#什么是脑裂"><span class="nav-number">1.6.2.1.</span> <span class="nav-text">什么是脑裂</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#解决方案"><span class="nav-number">1.6.2.2.</span> <span class="nav-text">解决方案</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#淘汰策略"><span class="nav-number">1.7.</span> <span class="nav-text">淘汰策略</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-使用的过期删除策略是什么"><span class="nav-number">1.7.1.</span> <span class="nav-text">Redis 使用的过期删除策略是什么</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#惰性删除策略"><span class="nav-number">1.7.1.1.</span> <span class="nav-text">惰性删除策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#定期删除策略"><span class="nav-number">1.7.1.2.</span> <span class="nav-text">定期删除策略</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-持久化时，对过期键会如何处理"><span class="nav-number">1.7.2.</span> <span class="nav-text">Redis 持久化时，对过期键会如何处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-主从模式中，对过期键会如何处理"><span class="nav-number">1.7.3.</span> <span class="nav-text">Redis 主从模式中，对过期键会如何处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-内存满了，会发生什么"><span class="nav-number">1.7.4.</span> <span class="nav-text">Redis 内存满了，会发生什么</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-内存淘汰策略"><span class="nav-number">1.7.5.</span> <span class="nav-text">Redis 内存淘汰策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#LRU"><span class="nav-number">1.7.5.1.</span> <span class="nav-text">LRU</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LFU"><span class="nav-number">1.7.5.2.</span> <span class="nav-text">LFU</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#缓存设计"><span class="nav-number">1.8.</span> <span class="nav-text">缓存设计</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#缓存雪崩、缓存击穿、缓存穿透"><span class="nav-number">1.8.1.</span> <span class="nav-text">缓存雪崩、缓存击穿、缓存穿透</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#缓存雪崩"><span class="nav-number">1.8.1.1.</span> <span class="nav-text">缓存雪崩</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#缓存击穿"><span class="nav-number">1.8.1.2.</span> <span class="nav-text">缓存击穿</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#缓存穿透"><span class="nav-number">1.8.1.3.</span> <span class="nav-text">缓存穿透</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#如何设计一个缓存策略，可以动态缓存热点数据"><span class="nav-number">1.8.2.</span> <span class="nav-text">如何设计一个缓存策略，可以动态缓存热点数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#常见的缓存更新策略"><span class="nav-number">1.8.3.</span> <span class="nav-text">常见的缓存更新策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Cache-Aside"><span class="nav-number">1.8.3.1.</span> <span class="nav-text">Cache Aside</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Read-Write-Through"><span class="nav-number">1.8.3.2.</span> <span class="nav-text">Read&#x2F;Write Through</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Write-Back"><span class="nav-number">1.8.3.3.</span> <span class="nav-text">Write Back</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分布式锁-1"><span class="nav-number">1.9.</span> <span class="nav-text">分布式锁</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis为什么不支持事务回滚"><span class="nav-number">1.10.</span> <span class="nav-text">Redis为什么不支持事务回滚</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <a href="/">
      <img class="site-author-image" itemprop="image" alt="Charispsychoma"
        src="/images/avatar.jpg">
    </a>
  <p class="site-author-name" itemprop="name">Charispsychoma</p>
  <div class="site-description" itemprop="description">Stay hungry. Stay foolish.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">40</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">35</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">39</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/IRVLIN" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;IRVLIN" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:irvlin0404@gmail.com" title="E-Mail → mailto:irvlin0404@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/charispsychoma" title="Zhihu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;charispsychoma" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i>Zhihu</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.instagram.com/irv.lin/" title="Instagram → https:&#x2F;&#x2F;www.instagram.com&#x2F;irv.lin&#x2F;" rel="noopener" target="_blank"><i class="fab fa-instagram fa-fw"></i>Instagram</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
<script>
    var now = new Date(); 
    function createtime() { 
        var grt= new Date("05/11/2020 14:44:44");//在此处修改你的建站时间
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = "已存活 "+dnum+" 天 "; 
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; 
    } 
setInterval("createtime()",250);
</script>

<div class="copyright">
  
  &copy; 2020 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Charispsychoma</span>
</div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
         访客数: <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        访问量: <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'BTYxjkQrcW0LVlgoggIJ2kD4-gzGzoHsz',
      appKey     : 'JJRnAk74iYw1AJ5GBVnXaT6b',
      placeholder: "欢迎评论～",
      avatar     : 'retro',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

    </div>

  <!-- require APlayer -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.6.0/style.css" />
  <script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script>
  <!-- require MetingJS -->
  <script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

  <meting-js
    server="netease" type="playlist" id="574119204" order="random" volume=0.5 fixed=true theme="#333">
  </meting-js>

  <script type="text/javascript" src="/js/clicklove.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/irvlin/CDN/js/jquery-3.4.1.min.js"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/00years/ribbon@v1.0/ribbon.min.js"></script>
  <script src="/live2d-widget/autoload.js"></script>
</body>
</html>
